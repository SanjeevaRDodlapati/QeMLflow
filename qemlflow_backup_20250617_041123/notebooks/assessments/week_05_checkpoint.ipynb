{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e503bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChemML Integration Setupimport chemmlprint(f'üß™ ChemML {chemml.__version__} loaded for this notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43940486",
   "metadata": {},
   "source": [
    "# Week 5 Checkpoint: Machine Learning Fundamentals for Drug Discovery\n",
    "\n",
    "## Learning Objectives Verification\n",
    "By the end of this week, you should be able to:\n",
    "- Implement regression and classification models for QSAR\n",
    "- Apply proper model validation and evaluation techniques\n",
    "- Perform hyperparameter tuning and model selection\n",
    "- Interpret model performance metrics in drug discovery context\n",
    "- Handle imbalanced datasets common in bioactivity prediction\n",
    "\n",
    "## Progress Tracking Dashboard\n",
    "**Week:** 5/12  \n",
    "**Module:** Machine Learning Fundamentals for Drug Discovery  \n",
    "**Estimated Time:** 10-14 hours  \n",
    "**Prerequisites:** Weeks 1-4 completed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d094bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.metrics import mean_squared_error, r2_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Progress tracking\n",
    "progress_tracker = {\n",
    "    'week': 5,\n",
    "    'completed_tasks': [],\n",
    "    'scores': {},\n",
    "    'time_spent': 0,\n",
    "    'challenges_faced': [],\n",
    "    'next_steps': []\n",
    "}\n",
    "\n",
    "print(\"Week 5 Checkpoint: Machine Learning Fundamentals for Drug Discovery\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa0e28d",
   "metadata": {},
   "source": [
    "## Task 1: QSAR Regression Model Development (25 points)\n",
    "\n",
    "Build and evaluate regression models to predict molecular properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec23c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: QSAR Regression Model Development\n",
    "print(\"Task 1: Building QSAR regression models...\")\n",
    "\n",
    "# Create synthetic dataset for LogP prediction\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate molecular descriptors (features)\n",
    "n_samples = 200\n",
    "molecular_weight = np.random.normal(350, 100, n_samples)\n",
    "n_rotatable_bonds = np.random.poisson(5, n_samples)\n",
    "n_aromatic_rings = np.random.poisson(2, n_samples)\n",
    "tpsa = np.random.normal(80, 30, n_samples)\n",
    "n_hbd = np.random.poisson(2, n_samples)\n",
    "n_hba = np.random.poisson(4, n_samples)\n",
    "\n",
    "# Create realistic LogP values based on molecular properties\n",
    "logp_base = (molecular_weight * 0.01 + \n",
    "             n_aromatic_rings * 0.5 - \n",
    "             tpsa * 0.02 - \n",
    "             n_hbd * 0.3 - \n",
    "             n_hba * 0.2 + \n",
    "             np.random.normal(0, 0.5, n_samples))\n",
    "\n",
    "# Create DataFrame\n",
    "qsar_data = pd.DataFrame({\n",
    "    'MW': molecular_weight,\n",
    "    'RotBonds': n_rotatable_bonds,\n",
    "    'AromaticRings': n_aromatic_rings,\n",
    "    'TPSA': tpsa,\n",
    "    'HBD': n_hbd,\n",
    "    'HBA': n_hba,\n",
    "    'LogP': logp_base\n",
    "})\n",
    "\n",
    "# Remove outliers\n",
    "qsar_data = qsar_data[(qsar_data['LogP'] >= -2) & (qsar_data['LogP'] <= 8)]\n",
    "qsar_data = qsar_data[(qsar_data['MW'] > 100) & (qsar_data['MW'] < 800)]\n",
    "\n",
    "print(f\"Dataset created with {len(qsar_data)} compounds\")\n",
    "print(\"\\nDataset statistics:\")\n",
    "print(qsar_data.describe().round(2))\n",
    "\n",
    "# Prepare features and target\n",
    "X = qsar_data.drop('LogP', axis=1)\n",
    "y = qsar_data['LogP']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define regression models\n",
    "models = {\n",
    "    'Linear Regression': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LinearRegression())\n",
    "    ]),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'SVM': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', SVR(kernel='rbf', C=1.0, gamma='scale'))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "model_results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Fit model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_r2 = r2_score(y_train, y_pred_train)\n",
    "    test_r2 = r2_score(y_test, y_pred_test)\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    model_results[name] = {\n",
    "        'train_r2': train_r2,\n",
    "        'test_r2': test_r2,\n",
    "        'train_rmse': train_rmse,\n",
    "        'test_rmse': test_rmse,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'y_pred_test': y_pred_test\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(model_results).T\n",
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(results_df[['train_r2', 'test_r2', 'test_rmse', 'cv_mean', 'cv_std']].round(3))\n",
    "\n",
    "# Visualize predictions vs actual\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, (name, results) in enumerate(model_results.items()):\n",
    "    axes[i].scatter(y_test, results['y_pred_test'], alpha=0.6)\n",
    "    axes[i].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    axes[i].set_xlabel('Actual LogP')\n",
    "    axes[i].set_ylabel('Predicted LogP')\n",
    "    axes[i].set_title(f'{name}\\nR¬≤ = {results[\"test_r2\"]:.3f}')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "progress_tracker['completed_tasks'].append('Task 1: QSAR Regression Model Development')\n",
    "progress_tracker['scores']['task_1'] = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18907c0",
   "metadata": {},
   "source": [
    "## Task 2: Binary Classification for Bioactivity Prediction (25 points)\n",
    "\n",
    "Build classification models to predict compound bioactivity (active/inactive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1ff765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Binary Classification for Bioactivity Prediction\n",
    "print(\"Task 2: Building bioactivity classification models...\")\n",
    "\n",
    "# Create binary classification dataset\n",
    "# Convert LogP to bioactivity labels (simplified example)\n",
    "# In reality, this would be experimental bioactivity data\n",
    "\n",
    "def create_bioactivity_labels(df):\n",
    "    \"\"\"\n",
    "    Create bioactivity labels based on molecular properties\n",
    "    This is a simplified example - real data would come from assays\n",
    "    \"\"\"\n",
    "    # Create a compound bioactivity score based on drug-like properties\n",
    "    activity_score = (\n",
    "        (df['MW'] <= 500).astype(int) * 0.2 +\n",
    "        (df['LogP'] <= 5).astype(int) * 0.2 +\n",
    "        (df['HBD'] <= 5).astype(int) * 0.2 +\n",
    "        (df['TPSA'] <= 140).astype(int) * 0.2 +\n",
    "        (df['RotBonds'] <= 10).astype(int) * 0.2 +\n",
    "        np.random.normal(0, 0.1, len(df))  # Add some noise\n",
    "    )\n",
    "    \n",
    "    # Convert to binary labels\n",
    "    # Active if score > 0.6, inactive otherwise\n",
    "    return (activity_score > 0.6).astype(int)\n",
    "\n",
    "# Create classification dataset\n",
    "y_class = create_bioactivity_labels(qsar_data)\n",
    "X_class = qsar_data.drop('LogP', axis=1)\n",
    "\n",
    "print(f\"Classification dataset created:\")\n",
    "print(f\"  Total compounds: {len(y_class)}\")\n",
    "print(f\"  Active compounds: {sum(y_class)} ({sum(y_class)/len(y_class)*100:.1f}%)\")\n",
    "print(f\"  Inactive compounds: {len(y_class)-sum(y_class)} ({(len(y_class)-sum(y_class))/len(y_class)*100:.1f}%)\")\n",
    "\n",
    "# Split data\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
    "    X_class, y_class, test_size=0.3, random_state=42, stratify=y_class\n",
    ")\n",
    "\n",
    "# Define classification models\n",
    "clf_models = {\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression(random_state=42))\n",
    "    ]),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', SVC(probability=True, random_state=42))\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Train and evaluate classification models\n",
    "clf_results = {}\n",
    "\n",
    "for name, model in clf_models.items():\n",
    "    # Fit model\n",
    "    model.fit(X_train_c, y_train_c)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred_c = model.predict(X_test_c)\n",
    "    y_prob_c = model.predict_proba(X_test_c)[:, 1]\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = model.score(X_test_c, y_test_c)\n",
    "    auc_score = roc_auc_score(y_test_c, y_prob_c)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_c, y_train_c, cv=5, scoring='roc_auc')\n",
    "    \n",
    "    clf_results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'auc': auc_score,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'y_pred': y_pred_c,\n",
    "        'y_prob': y_prob_c\n",
    "    }\n",
    "\n",
    "# Display classification results\n",
    "clf_results_df = pd.DataFrame(clf_results).T\n",
    "print(\"\\nClassification Model Performance:\")\n",
    "print(clf_results_df[['accuracy', 'auc', 'cv_mean', 'cv_std']].round(3))\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for name, results in clf_results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test_c, results['y_prob'])\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {results[\"auc\"]:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Bioactivity Classification')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, (name, results) in enumerate(clf_results.items()):\n",
    "    cm = confusion_matrix(y_test_c, results['y_pred'])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', ax=axes[i], cmap='Blues')\n",
    "    axes[i].set_title(f'{name} Confusion Matrix')\n",
    "    axes[i].set_xlabel('Predicted')\n",
    "    axes[i].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "progress_tracker['completed_tasks'].append('Task 2: Binary Classification for Bioactivity Prediction')\n",
    "progress_tracker['scores']['task_2'] = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7f3298",
   "metadata": {},
   "source": [
    "## Task 3: Hyperparameter Tuning and Model Selection (25 points)\n",
    "\n",
    "Optimize model performance through systematic hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f85fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Hyperparameter Tuning and Model Selection\n",
    "print(\"Task 3: Hyperparameter tuning and model optimization...\")\n",
    "\n",
    "# Define hyperparameter grids for different models\n",
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'SVM': {\n",
    "        'model__C': [0.1, 1, 10, 100],\n",
    "        'model__gamma': ['scale', 'auto', 0.001, 0.01, 0.1]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning for regression (Random Forest)\n",
    "print(\"\\nTuning Random Forest for LogP prediction...\")\n",
    "\n",
    "rf_reg = RandomForestRegressor(random_state=42)\n",
    "grid_search_reg = GridSearchCV(\n",
    "    rf_reg, \n",
    "    param_grids['Random Forest'], \n",
    "    cv=5, \n",
    "    scoring='r2',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_reg.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters: {grid_search_reg.best_params_}\")\n",
    "print(f\"Best CV score: {grid_search_reg.best_score_:.3f}\")\n",
    "\n",
    "# Evaluate tuned model\n",
    "best_rf_reg = grid_search_reg.best_estimator_\n",
    "y_pred_tuned = best_rf_reg.predict(X_test)\n",
    "tuned_r2 = r2_score(y_test, y_pred_tuned)\n",
    "tuned_rmse = np.sqrt(mean_squared_error(y_test, y_pred_tuned))\n",
    "\n",
    "print(f\"Tuned model test R¬≤: {tuned_r2:.3f}\")\n",
    "print(f\"Tuned model test RMSE: {tuned_rmse:.3f}\")\n",
    "\n",
    "# Hyperparameter tuning for classification (SVM)\n",
    "print(\"\\nTuning SVM for bioactivity classification...\")\n",
    "\n",
    "svm_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', SVC(probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "grid_search_clf = GridSearchCV(\n",
    "    svm_clf, \n",
    "    param_grids['SVM'], \n",
    "    cv=5, \n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_clf.fit(X_train_c, y_train_c)\n",
    "\n",
    "print(f\"Best parameters: {grid_search_clf.best_params_}\")\n",
    "print(f\"Best CV score: {grid_search_clf.best_score_:.3f}\")\n",
    "\n",
    "# Evaluate tuned classifier\n",
    "best_svm_clf = grid_search_clf.best_estimator_\n",
    "y_pred_tuned_c = best_svm_clf.predict(X_test_c)\n",
    "y_prob_tuned_c = best_svm_clf.predict_proba(X_test_c)[:, 1]\n",
    "tuned_accuracy = best_svm_clf.score(X_test_c, y_test_c)\n",
    "tuned_auc = roc_auc_score(y_test_c, y_prob_tuned_c)\n",
    "\n",
    "print(f\"Tuned classifier accuracy: {tuned_accuracy:.3f}\")\n",
    "print(f\"Tuned classifier AUC: {tuned_auc:.3f}\")\n",
    "\n",
    "# Feature importance analysis for tuned Random Forest\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': best_rf_reg.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
    "plt.title('Feature Importance - Tuned Random Forest (LogP Prediction)')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Learning curves to check for overfitting\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "def plot_learning_curve(estimator, X, y, title, cv=5):\n",
    "    \"\"\"\n",
    "    Plot learning curves to diagnose overfitting\n",
    "    \"\"\"\n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=-1, \n",
    "        train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "        scoring='r2' if 'Regressor' in str(type(estimator)) else 'roc_auc'\n",
    "    )\n",
    "    \n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_sizes, train_mean, 'o-', label='Training Score')\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1)\n",
    "    plt.plot(train_sizes, val_mean, 'o-', label='Validation Score')\n",
    "    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1)\n",
    "    \n",
    "    plt.xlabel('Training Set Size')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title(f'Learning Curve - {title}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# Plot learning curves for tuned models\n",
    "plot_learning_curve(best_rf_reg, X_train, y_train, 'Tuned Random Forest (Regression)')\n",
    "plot_learning_curve(best_svm_clf, X_train_c, y_train_c, 'Tuned SVM (Classification)')\n",
    "\n",
    "progress_tracker['completed_tasks'].append('Task 3: Hyperparameter Tuning and Model Selection')\n",
    "progress_tracker['scores']['task_3'] = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377935f7",
   "metadata": {},
   "source": [
    "## Task 4: Handling Imbalanced Data in Drug Discovery (25 points)\n",
    "\n",
    "Address class imbalance issues common in bioactivity datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be524998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Handling Imbalanced Data in Drug Discovery\n",
    "print(\"Task 4: Handling imbalanced bioactivity data...\")\n",
    "\n",
    "# Create a more realistic imbalanced dataset\n",
    "# In drug discovery, active compounds are often much rarer\n",
    "def create_imbalanced_dataset(df, active_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Create an imbalanced dataset mimicking real drug discovery scenarios\n",
    "    \"\"\"\n",
    "    n_total = len(df)\n",
    "    n_active = int(n_total * active_ratio)\n",
    "    \n",
    "    # Create labels with strong bias toward drug-like properties for actives\n",
    "    activity_prob = (\n",
    "        (df['MW'] <= 450).astype(int) * 0.3 +\n",
    "        (df['LogP'] >= 1).astype(int) * (df['LogP'] <= 4).astype(int) * 0.3 +\n",
    "        (df['HBD'] <= 3).astype(int) * 0.2 +\n",
    "        (df['TPSA'] <= 120).astype(int) * 0.2\n",
    "    )\n",
    "    \n",
    "    # Add noise and make it more selective\n",
    "    activity_prob += np.random.normal(0, 0.1, len(df))\n",
    "    \n",
    "    # Select top compounds as active\n",
    "    active_threshold = np.percentile(activity_prob, 100 - active_ratio * 100)\n",
    "    labels = (activity_prob >= active_threshold).astype(int)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "# Create imbalanced dataset\n",
    "y_imbal = create_imbalanced_dataset(qsar_data, active_ratio=0.15)\n",
    "X_imbal = qsar_data.drop('LogP', axis=1)\n",
    "\n",
    "print(f\"Imbalanced dataset created:\")\n",
    "print(f\"  Total compounds: {len(y_imbal)}\")\n",
    "print(f\"  Active compounds: {sum(y_imbal)} ({sum(y_imbal)/len(y_imbal)*100:.1f}%)\")\n",
    "print(f\"  Inactive compounds: {len(y_imbal)-sum(y_imbal)} ({(len(y_imbal)-sum(y_imbal))/len(y_imbal)*100:.1f}%)\")\n",
    "\n",
    "# Split data\n",
    "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(\n",
    "    X_imbal, y_imbal, test_size=0.3, random_state=42, stratify=y_imbal\n",
    ")\n",
    "\n",
    "# Compare approaches for handling imbalanced data\n",
    "approaches = {\n",
    "    'Baseline': {\n",
    "        'model': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        'X_train': X_train_i,\n",
    "        'y_train': y_train_i\n",
    "    },\n",
    "    'Class Weight': {\n",
    "        'model': RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
    "        'X_train': X_train_i,\n",
    "        'y_train': y_train_i\n",
    "    }\n",
    "}\n",
    "\n",
    "# SMOTE oversampling\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train_i, y_train_i)\n",
    "\n",
    "approaches['SMOTE'] = {\n",
    "    'model': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'X_train': X_train_smote,\n",
    "    'y_train': y_train_smote\n",
    "}\n",
    "\n",
    "print(f\"\\nAfter SMOTE:\")\n",
    "print(f\"  Training set size: {len(y_train_smote)}\")\n",
    "print(f\"  Active: {sum(y_train_smote)} ({sum(y_train_smote)/len(y_train_smote)*100:.1f}%)\")\n",
    "print(f\"  Inactive: {len(y_train_smote)-sum(y_train_smote)} ({(len(y_train_smote)-sum(y_train_smote))/len(y_train_smote)*100:.1f}%)\")\n",
    "\n",
    "# Evaluate all approaches\n",
    "imbalanced_results = {}\n",
    "\n",
    "for name, config in approaches.items():\n",
    "    # Train model\n",
    "    model = config['model']\n",
    "    model.fit(config['X_train'], config['y_train'])\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test_i)\n",
    "    y_prob = model.predict_proba(X_test_i)[:, 1]\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score, balanced_accuracy_score\n",
    "    \n",
    "    accuracy = model.score(X_test_i, y_test_i)\n",
    "    balanced_acc = balanced_accuracy_score(y_test_i, y_pred)\n",
    "    precision = precision_score(y_test_i, y_pred)\n",
    "    recall = recall_score(y_test_i, y_pred)\n",
    "    f1 = f1_score(y_test_i, y_pred)\n",
    "    auc = roc_auc_score(y_test_i, y_prob)\n",
    "    \n",
    "    imbalanced_results[name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'balanced_accuracy': balanced_acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'y_prob': y_prob\n",
    "    }\n",
    "\n",
    "# Display results\n",
    "imbal_results_df = pd.DataFrame(imbalanced_results).T\n",
    "print(\"\\nImbalanced Data Handling Results:\")\n",
    "print(imbal_results_df[['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'auc']].round(3))\n",
    "\n",
    "# Plot comparison\n",
    "metrics = ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1', 'auc']\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.25\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "for i, (approach, results) in enumerate(imbalanced_results.items()):\n",
    "    values = [results[metric] for metric in metrics]\n",
    "    ax.bar(x + i*width, values, width, label=approach)\n",
    "\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Performance Comparison: Handling Imbalanced Data')\n",
    "ax.set_xticks(x + width)\n",
    "ax.set_xticklabels(metrics, rotation=45)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC curves for imbalanced data approaches\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for name, results in imbalanced_results.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test_i, results['y_prob'])\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {results[\"auc\"]:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves: Imbalanced Data Handling Approaches')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Analysis and recommendations\n",
    "print(\"\\nAnalysis and Recommendations:\")\n",
    "best_f1 = max(imbalanced_results.items(), key=lambda x: x[1]['f1'])\n",
    "best_recall = max(imbalanced_results.items(), key=lambda x: x[1]['recall'])\n",
    "best_auc = max(imbalanced_results.items(), key=lambda x: x[1]['auc'])\n",
    "\n",
    "print(f\"  Best F1-score: {best_f1[0]} ({best_f1[1]['f1']:.3f})\")\n",
    "print(f\"  Best Recall: {best_recall[0]} ({best_recall[1]['recall']:.3f})\")\n",
    "print(f\"  Best AUC: {best_auc[0]} ({best_auc[1]['auc']:.3f})\")\n",
    "\n",
    "print(\"\\n  Key Insights:\")\n",
    "print(\"  - SMOTE often improves recall for minority class (active compounds)\")\n",
    "print(\"  - Class weighting is computationally efficient alternative\")\n",
    "print(\"  - Consider domain-specific metrics (precision vs recall trade-off)\")\n",
    "print(\"  - AUC-ROC is less sensitive to class imbalance than accuracy\")\n",
    "\n",
    "progress_tracker['completed_tasks'].append('Task 4: Handling Imbalanced Data')\n",
    "progress_tracker['scores']['task_4'] = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea1efba",
   "metadata": {},
   "source": [
    "## Self-Assessment and Reflection\n",
    "\n",
    "Complete this self-assessment to evaluate your understanding of machine learning fundamentals for drug discovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1befaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-Assessment Questions\n",
    "print(\"SELF-ASSESSMENT: Machine Learning Fundamentals for Drug Discovery\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "assessment_questions = [\n",
    "    {\n",
    "        'question': 'Which metric is most appropriate for evaluating a highly imbalanced bioactivity dataset?',\n",
    "        'options': ['A) Accuracy', 'B) AUC-ROC', 'C) Mean Squared Error', 'D) R-squared'],\n",
    "        'correct': 'B',\n",
    "        'explanation': 'AUC-ROC is less sensitive to class imbalance and better evaluates model discrimination.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'What is the primary risk of overfitting in drug discovery models?',\n",
    "        'options': ['A) Poor training performance', 'B) High computational cost', \n",
    "                   'C) Poor generalization to new compounds', 'D) Slow prediction speed'],\n",
    "        'correct': 'C',\n",
    "        'explanation': 'Overfitted models perform well on training data but fail on new, unseen compounds.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'Why is cross-validation particularly important in QSAR modeling?',\n",
    "        'options': ['A) To speed up training', 'B) To assess model stability and generalizability', \n",
    "                   'C) To reduce memory usage', 'D) To improve feature selection'],\n",
    "        'correct': 'B',\n",
    "        'explanation': 'Cross-validation provides robust estimates of model performance on unseen data.'\n",
    "    },\n",
    "    {\n",
    "        'question': 'When would you prefer high recall over high precision in drug discovery?',\n",
    "        'options': ['A) When screening for toxic compounds', 'B) When identifying drug candidates', \n",
    "                   'C) When optimizing lead compounds', 'D) Never'],\n",
    "        'correct': 'B',\n",
    "        'explanation': 'High recall ensures you don\\'t miss potential drug candidates (minimize false negatives).'\n",
    "    },\n",
    "    {\n",
    "        'question': 'What is the main advantage of Random Forest over linear models for molecular data?',\n",
    "        'options': ['A) Faster training', 'B) Better interpretability', \n",
    "                   'C) Handling non-linear relationships', 'D) Lower memory usage'],\n",
    "        'correct': 'C',\n",
    "        'explanation': 'Random Forest can capture complex non-linear relationships between molecular features.'\n",
    "    }\n",
    "]\n",
    "\n",
    "score = 0\n",
    "for i, q in enumerate(assessment_questions, 1):\n",
    "    print(f\"\\nQuestion {i}: {q['question']}\")\n",
    "    for option in q['options']:\n",
    "        print(f\"  {option}\")\n",
    "    \n",
    "    # For demonstration, we'll show the correct answer\n",
    "    print(f\"\\nCorrect Answer: {q['correct']}\")\n",
    "    print(f\"Explanation: {q['explanation']}\")\n",
    "    score += 1  # Assuming correct for progress tracking\n",
    "\n",
    "assessment_score = (score / len(assessment_questions)) * 100\n",
    "progress_tracker['scores']['self_assessment'] = assessment_score\n",
    "\n",
    "print(f\"\\nSelf-Assessment Score: {assessment_score:.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59dfd75",
   "metadata": {},
   "source": [
    "## Week 5 Progress Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8696c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall progress\n",
    "total_score = sum(progress_tracker['scores'].values())\n",
    "max_score = 125  # 4 tasks √ó 25 points + 25 points assessment\n",
    "overall_percentage = (total_score / max_score) * 100\n",
    "\n",
    "progress_tracker['overall_score'] = overall_percentage\n",
    "progress_tracker['time_spent'] = 12  # Estimated hours\n",
    "\n",
    "print(\"WEEK 5 PROGRESS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Overall Score: {overall_percentage:.1f}%\")\n",
    "print(f\"Time Spent: {progress_tracker['time_spent']} hours\")\n",
    "print(f\"Tasks Completed: {len(progress_tracker['completed_tasks'])}/4\")\n",
    "\n",
    "print(\"\\nTask Breakdown:\")\n",
    "for task, score in progress_tracker['scores'].items():\n",
    "    if task != 'self_assessment':\n",
    "        print(f\"  {task}: {score}/25 points\")\n",
    "    else:\n",
    "        print(f\"  {task}: {score:.0f}%\")\n",
    "\n",
    "print(\"\\nKey Learning Outcomes Achieved:\")\n",
    "outcomes = [\n",
    "    \"‚úì Built and evaluated QSAR regression models\",\n",
    "    \"‚úì Implemented classification for bioactivity prediction\",\n",
    "    \"‚úì Performed systematic hyperparameter tuning\",\n",
    "    \"‚úì Addressed class imbalance in drug discovery data\",\n",
    "    \"‚úì Applied proper validation and evaluation techniques\",\n",
    "    \"‚úì Interpreted model performance in drug discovery context\"\n",
    "]\n",
    "for outcome in outcomes:\n",
    "    print(f\"  {outcome}\")\n",
    "\n",
    "print(\"\\nNext Week (Week 6) Preview:\")\n",
    "print(\"  üìö Topic: Deep Learning Applications in Drug Discovery\")\n",
    "print(\"  üéØ Focus: Neural networks, CNNs for molecular data\")\n",
    "print(\"  üí° Skills: Deep learning architectures, model interpretation\")\n",
    "print(\"  üî¨ Practice: Build neural networks for ADMET prediction\")\n",
    "\n",
    "# Portfolio development checkpoint\n",
    "print(\"\\nPortfolio Development Checkpoint:\")\n",
    "print(\"  üìä Implement ML pipeline in your multi-target project\")\n",
    "print(\"  üîß Add model comparison and validation framework\")\n",
    "print(\"  üìà Document hyperparameter tuning results\")\n",
    "print(\"  üéØ Optimize models for your specific targets\")\n",
    "print(\"  ‚öñÔ∏è Address any class imbalance in your datasets\")\n",
    "\n",
    "# Advanced challenges for strong students\n",
    "print(\"\\nAdvanced Challenges (Optional):\")\n",
    "print(\"  üöÄ Implement ensemble methods (voting, stacking)\")\n",
    "print(\"  üìä Explore Bayesian optimization for hyperparameter tuning\")\n",
    "print(\"  üî¨ Try different evaluation strategies (time-series, group-based CV)\")\n",
    "print(\"  üí° Implement cost-sensitive learning for different error types\")\n",
    "\n",
    "# Save progress\n",
    "import json\n",
    "with open('week_05_progress.json', 'w') as f:\n",
    "    # Convert numpy arrays to lists for JSON serialization\n",
    "    clean_tracker = progress_tracker.copy()\n",
    "    json.dump(clean_tracker, f, indent=2)\n",
    "\n",
    "print(\"\\n‚úÖ Week 5 checkpoint completed! Progress saved to week_05_progress.json\")\n",
    "print(\"üìù Remember to update your learning journal with ML insights\")\n",
    "print(\"üöÄ Ready to dive into Deep Learning in Week 6!\")"
   ]
  }
 ],
 "metadata": {
  "chemml": {
   "integrated": true,
   "integration_date": "2025-06-15T23:50:25.000289",
   "version": "1.0"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
