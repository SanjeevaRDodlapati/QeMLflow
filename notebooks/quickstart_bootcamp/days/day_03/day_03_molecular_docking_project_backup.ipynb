{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21624319",
   "metadata": {},
   "source": [
    "# Day 3 Project: Molecular Docking & Virtual Screening üéØ\n",
    "\n",
    "## Structure-Based Drug Discovery Pipeline - 6 Hours of Intensive Coding\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Master molecular docking with AutoDock Vina and GNINA\n",
    "- Build automated virtual screening pipelines\n",
    "- Implement binding site analysis and druggability assessment\n",
    "- Create ML-enhanced docking workflows\n",
    "\n",
    "**Skills Building Path:**\n",
    "- **Section 1:** Protein Structure Analysis & Preparation (1.5 hours)\n",
    "- **Section 2:** Molecular Docking Implementation (1.5 hours)\n",
    "- **Section 3:** Virtual Screening Pipeline (1.5 hours)\n",
    "- **Section 4:** ML-Enhanced Scoring Functions (1 hour)\n",
    "- **Section 5:** Integration & Drug Discovery Workflow (0.5 hours)\n",
    "\n",
    "**Cross-References:**\n",
    "- üîó **Day 2:** Builds on molecular representations and deep learning\n",
    "- üîó **Week 8 Checkpoint:** Virtual screening and drug discovery\n",
    "- üîó **Week 9 Checkpoint:** Advanced molecular modeling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a48f50",
   "metadata": {},
   "source": [
    "## Section 1: Protein Structure Analysis & Preparation (1.5 hours)\n",
    "\n",
    "**Objective:** Master protein structure handling, binding site identification, and structure preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeab17ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Assessment Framework Setup for Day 3: Molecular Docking & Virtual Screening\n",
    "from datetime import datetime\n",
    "try:\n",
    "    from assessment_framework import BootcampAssessment, create_widget, create_dashboard\n",
    "    print(\"‚úÖ Assessment framework loaded successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Assessment framework not found - creating basic tracking\")\n",
    "    class BootcampAssessment:\n",
    "        def __init__(self, student_name, day):\n",
    "            self.student_name = student_name\n",
    "            self.day = day\n",
    "            self.activities = []\n",
    "        def record_activity(self, activity, data):\n",
    "            self.activities.append({\"activity\": activity, \"data\": data, \"timestamp\": datetime.now()})\n",
    "        def get_progress_summary(self):\n",
    "            return {\"overall_score\": 0.75, \"section_scores\": {}}\n",
    "    def create_widget(assessment, section, concepts, activities, time_target=90, section_type=\"assessment\"):\n",
    "        return type('MockWidget', (), {'display': lambda: print(f\"üìã {section} - Interactive assessment widget\")})()  \n",
    "\n",
    "# Initialize Assessment System for Day 3\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ DAY 3: MOLECULAR DOCKING & VIRTUAL SCREENING\")\n",
    "print(\"üìä Assessment Framework Initialization\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Student identification and tracking setup\n",
    "student_name = input(\"üéì Please enter your name for progress tracking: \")\n",
    "if not student_name.strip():\n",
    "    student_name = \"Student_\" + datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "\n",
    "print(f\"üë§ Welcome {student_name}!\")\n",
    "print(\"üöÄ Initializing Day 3 assessment session...\")\n",
    "\n",
    "# Create assessment instance for Day 3\n",
    "day3_assessment = BootcampAssessment(student_name, day=3)\n",
    "\n",
    "# Define Day 3 specialization tracks\n",
    "day3_tracks = {\n",
    "    \"docking_expert\": \"Molecular Docking Expert - Master AutoDock Vina & GNINA\",\n",
    "    \"screening_specialist\": \"Virtual Screening Specialist - High-throughput workflows\", \n",
    "    \"ml_enhanced\": \"ML-Enhanced Docking - Machine learning scoring functions\",\n",
    "    \"drug_discovery\": \"Drug Discovery Pipeline - End-to-end discovery workflows\"\n",
    "}\n",
    "\n",
    "print(\"\\nüéØ Available Specialization Tracks for Day 3:\")\n",
    "for key, description in day3_tracks.items():\n",
    "    print(f\"  ‚Ä¢ {key}: {description}\")\n",
    "\n",
    "selected_track = input(\"\\nüéØ Choose your specialization track (or press Enter for 'docking_expert'): \").strip()\n",
    "if not selected_track or selected_track not in day3_tracks:\n",
    "    selected_track = \"docking_expert\"\n",
    "\n",
    "print(f\"‚úÖ Selected track: {day3_tracks[selected_track]}\")\n",
    "\n",
    "# Record initial activity\n",
    "day3_assessment.record_activity(\"day_start\", {\n",
    "    \"specialization_track\": selected_track,\n",
    "    \"track_description\": day3_tracks[selected_track],\n",
    "    \"day\": 3,\n",
    "    \"focus\": \"molecular_docking_virtual_screening\"\n",
    "})\n",
    "\n",
    "print(f\"\\nüìä Day 3 assessment tracking initialized!\")\n",
    "print(f\"üéØ Focus: Molecular Docking & Virtual Screening\")\n",
    "print(f\"üéì Student: {student_name}\")\n",
    "print(f\"üìà Track: {day3_tracks[selected_track]}\")\n",
    "print(\"\\n‚è∞ Ready to begin Section 1: Protein Structure Analysis & Preparation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cea0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced imports for molecular docking and structure analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem, Descriptors, Draw, rdMolDescriptors\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "import subprocess\n",
    "import os\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# BioPython for protein structure analysis\n",
    "try:\n",
    "    from Bio.PDB import PDBParser, PDBIO, Select\n",
    "    from Bio.PDB.DSSP import DSSP\n",
    "    from Bio.PDB.PDBList import PDBList\n",
    "    BIOPYTHON_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  BioPython not available. Installing...\")\n",
    "    subprocess.run([\"pip\", \"install\", \"biopython\"], check=True)\n",
    "    from Bio.PDB import PDBParser, PDBIO, Select\n",
    "    from Bio.PDB.DSSP import DSSP\n",
    "    from Bio.PDB.PDBList import PDBList\n",
    "    BIOPYTHON_AVAILABLE = True\n",
    "\n",
    "# PyMOL Python API (if available)\n",
    "try:\n",
    "    import pymol\n",
    "    PYMOL_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  PyMOL not available for advanced visualization\")\n",
    "    PYMOL_AVAILABLE = False\n",
    "\n",
    "print(\"üéØ Starting Day 3: Molecular Docking & Virtual Screening\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"‚úÖ BioPython: {'Available' if BIOPYTHON_AVAILABLE else 'Not Available'}\")\n",
    "print(f\"‚úÖ PyMOL: {'Available' if PYMOL_AVAILABLE else 'Not Available'}\")\n",
    "\n",
    "# Create working directories\n",
    "os.makedirs('structures', exist_ok=True)\n",
    "os.makedirs('ligands', exist_ok=True)\n",
    "os.makedirs('docking_results', exist_ok=True)\n",
    "print(\"‚úÖ Working directories created\")\n",
    "\n",
    "# ASSESSMENT FRAMEWORK INITIALIZATION\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéì DAY 3 ASSESSMENT FRAMEWORK INITIALIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    from assessment_framework import create_assessment\n",
    "    print(\"‚úÖ Assessment framework loaded successfully\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Assessment framework not found. Please ensure assessment_framework.py is available.\")\n",
    "    print(\"üìÅ Expected location: same directory as this notebook\")\n",
    "    # Create a basic assessment object for fallback\n",
    "    class BasicAssessment:\n",
    "        def start_section(self, section): pass\n",
    "        def end_section(self, section): pass\n",
    "        def record_activity(self, activity, result, metadata=None): pass\n",
    "        def get_progress_summary(self): return {\"overall_score\": 0.0, \"section_scores\": {}}\n",
    "        def get_comprehensive_report(self): return {\"activities\": []}\n",
    "        def save_final_report(self, filename): pass\n",
    "    \n",
    "    def create_assessment(student_id, track=\"molecular_docking\"):\n",
    "        return BasicAssessment()\n",
    "\n",
    "# Student Information Collection\n",
    "print(\"\\nüìù Student Assessment Setup:\")\n",
    "student_id = input(\"Enter your student ID: \").strip()\n",
    "if not student_id:\n",
    "    student_id = f\"student_day3_{np.random.randint(1000, 9999)}\"\n",
    "    print(f\"Generated ID: {student_id}\")\n",
    "\n",
    "# Track Selection\n",
    "print(\"\\nüéØ Select your learning track:\")\n",
    "print(\"1. üß¨ Computational Chemist\")\n",
    "print(\"2. üíä Drug Discovery Researcher\") \n",
    "print(\"3. ü§ñ Cheminformatics Developer\")\n",
    "print(\"4. üìä Bioinformatics Analyst\")\n",
    "\n",
    "track_choice = input(\"Enter choice (1-4): \")\n",
    "\n",
    "\n",
    "track_map = {\n",
    "    \"1\": \"computational_chemist\",\n",
    "    \"2\": \"drug_discovery\", \n",
    "    \"3\": \"cheminformatics_dev\",\n",
    "    \"4\": \"bioinformatics\"\n",
    "}\n",
    "selected_track = track_map.get(track_choice, \"computational_chemist\")\n",
    "\n",
    "print(f\"‚úÖ Track selected: {selected_track.replace('_', ' ').title()}\")\n",
    "\n",
    "# Initialize Assessment System\n",
    "assessment = create_assessment(student_id, selected_track)\n",
    "\n",
    "print(f\"\\nüéØ Day 3 Assessment System Initialized\")\n",
    "print(f\"üë§ Student: {student_id}\")\n",
    "print(f\"üìä Track: {selected_track.replace('_', ' ').title()}\")\n",
    "print(f\"üìÖ Module: Molecular Docking & Virtual Screening\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d023b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protein Structure Analyzer Class\n",
    "class ProteinStructureAnalyzer:\n",
    "    \"\"\"Comprehensive protein structure analysis and preparation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.parser = PDBParser(QUIET=True)\n",
    "        self.pdb_list = PDBList()\n",
    "        \n",
    "    def download_structure(self, pdb_id, save_dir='structures'):\n",
    "        \"\"\"Download PDB structure\"\"\"\n",
    "        try:\n",
    "            # Download PDB file\n",
    "            filename = self.pdb_list.retrieve_pdb_file(pdb_id, pdir=save_dir, file_format='pdb')\n",
    "            \n",
    "            # Rename to standard format\n",
    "            new_filename = os.path.join(save_dir, f\"{pdb_id.lower()}.pdb\")\n",
    "            if os.path.exists(filename):\n",
    "                os.rename(filename, new_filename)\n",
    "                return new_filename\n",
    "            else:\n",
    "                print(f\"‚ùå Failed to download {pdb_id}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error downloading {pdb_id}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def analyze_structure(self, pdb_file):\n",
    "        \"\"\"Comprehensive structure analysis\"\"\"\n",
    "        try:\n",
    "            structure = self.parser.get_structure('protein', pdb_file)\n",
    "            \n",
    "            analysis = {\n",
    "                'chains': [],\n",
    "                'residues': [],\n",
    "                'atoms': 0,\n",
    "                'hetero_atoms': [],\n",
    "                'water_molecules': 0,\n",
    "                'ligands': [],\n",
    "                'binding_sites': []\n",
    "            }\n",
    "            \n",
    "            for model in structure:\n",
    "                for chain in model:\n",
    "                    chain_info = {\n",
    "                        'id': chain.id,\n",
    "                        'residues': len(list(chain.get_residues())),\n",
    "                        'atoms': len(list(chain.get_atoms()))\n",
    "                    }\n",
    "                    analysis['chains'].append(chain_info)\n",
    "                    \n",
    "                    for residue in chain:\n",
    "                        res_name = residue.get_resname()\n",
    "                        res_id = residue.get_id()\n",
    "                        \n",
    "                        if res_id[0] == ' ':  # Standard residue\n",
    "                            analysis['residues'].append(res_name)\n",
    "                            analysis['atoms'] += len(list(residue.get_atoms()))\n",
    "                        elif res_id[0] == 'W':  # Water\n",
    "                            analysis['water_molecules'] += 1\n",
    "                        else:  # Hetero atoms (ligands, ions, etc.)\n",
    "                            if res_name not in ['HOH', 'WAT']:  # Exclude water\n",
    "                                ligand_info = {\n",
    "                                    'name': res_name,\n",
    "                                    'chain': chain.id,\n",
    "                                    'position': res_id[1],\n",
    "                                    'atoms': len(list(residue.get_atoms()))\n",
    "                                }\n",
    "                                analysis['ligands'].append(ligand_info)\n",
    "                            \n",
    "                            analysis['hetero_atoms'].append(res_name)\n",
    "            \n",
    "            return analysis\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error analyzing structure: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def find_binding_sites(self, pdb_file, ligand_name=None, distance_cutoff=5.0):\n",
    "        \"\"\"Identify potential binding sites\"\"\"\n",
    "        try:\n",
    "            structure = self.parser.get_structure('protein', pdb_file)\n",
    "            binding_sites = []\n",
    "            \n",
    "            for model in structure:\n",
    "                for chain in model:\n",
    "                    for residue in chain:\n",
    "                        res_id = residue.get_id()\n",
    "                        res_name = residue.get_resname()\n",
    "                        \n",
    "                        # If ligand specified, find residues near it\n",
    "                        if ligand_name and res_name == ligand_name:\n",
    "                            ligand_atoms = list(residue.get_atoms())\n",
    "                            nearby_residues = []\n",
    "                            \n",
    "                            # Find nearby protein residues\n",
    "                            for other_chain in model:\n",
    "                                for other_residue in other_chain:\n",
    "                                    if other_residue.get_id()[0] == ' ':  # Protein residue\n",
    "                                        min_distance = float('inf')\n",
    "                                        \n",
    "                                        for ligand_atom in ligand_atoms:\n",
    "                                            for protein_atom in other_residue.get_atoms():\n",
    "                                                distance = ligand_atom - protein_atom\n",
    "                                                min_distance = min(min_distance, distance)\n",
    "                                        \n",
    "                                        if min_distance <= distance_cutoff:\n",
    "                                            nearby_residues.append({\n",
    "                                                'residue': other_residue.get_resname(),\n",
    "                                                'chain': other_chain.id,\n",
    "                                                'position': other_residue.get_id()[1],\n",
    "                                                'distance': min_distance\n",
    "                                            })\n",
    "                            \n",
    "                            binding_sites.append({\n",
    "                                'ligand': ligand_name,\n",
    "                                'chain': chain.id,\n",
    "                                'position': res_id[1],\n",
    "                                'nearby_residues': nearby_residues\n",
    "                            })\n",
    "            \n",
    "            return binding_sites\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error finding binding sites: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def prepare_receptor(self, pdb_file, output_file, remove_waters=True, remove_ligands=False):\n",
    "        \"\"\"Prepare receptor for docking\"\"\"\n",
    "        try:\n",
    "            structure = self.parser.get_structure('protein', pdb_file)\n",
    "            \n",
    "            class ReceptorSelect(Select):\n",
    "                def accept_residue(self, residue):\n",
    "                    res_id = residue.get_id()\n",
    "                    res_name = residue.get_resname()\n",
    "                    \n",
    "                    # Remove waters if requested\n",
    "                    if remove_waters and res_name in ['HOH', 'WAT']:\n",
    "                        return False\n",
    "                    \n",
    "                    # Remove ligands if requested\n",
    "                    if remove_ligands and res_id[0] not in [' ', 'W']:\n",
    "                        return False\n",
    "                    \n",
    "                    # Keep protein residues\n",
    "                    if res_id[0] == ' ':\n",
    "                        return True\n",
    "                    \n",
    "                    # Keep specific ions/cofactors\n",
    "                    keep_hetero = ['MG', 'ZN', 'CA', 'FE', 'MN', 'NAD', 'FAD', 'HEME']\n",
    "                    if res_name in keep_hetero:\n",
    "                        return True\n",
    "                    \n",
    "                    return False\n",
    "            \n",
    "            # Save cleaned structure\n",
    "            io = PDBIO()\n",
    "            io.set_structure(structure)\n",
    "            io.save(output_file, ReceptorSelect())\n",
    "            \n",
    "            print(f\"‚úÖ Receptor prepared: {output_file}\")\n",
    "            return output_file\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error preparing receptor: {e}\")\n",
    "            return None\n",
    "\n",
    "# Initialize analyzer\n",
    "analyzer = ProteinStructureAnalyzer()\n",
    "print(\"‚úÖ Protein Structure Analyzer initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6d58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and analyze example protein structures\n",
    "target_proteins = [\n",
    "    {'pdb_id': '3HTB', 'name': 'HIV-1 Protease', 'ligand': 'T27'},\n",
    "    {'pdb_id': '1HSG', 'name': 'HIV-1 Protease (classic)', 'ligand': 'MK1'},\n",
    "    {'pdb_id': '4DFR', 'name': 'Dihydrofolate Reductase', 'ligand': 'FOL'}\n",
    "]\n",
    "\n",
    "print(\"üß¨ Downloading and Analyzing Target Proteins:\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "protein_data = {}\n",
    "\n",
    "for protein in target_proteins:\n",
    "    pdb_id = protein['pdb_id']\n",
    "    name = protein['name']\n",
    "    \n",
    "    print(f\"\\nüì• Processing {name} ({pdb_id})...\")\n",
    "    \n",
    "    # Download structure\n",
    "    pdb_file = analyzer.download_structure(pdb_id)\n",
    "    \n",
    "    if pdb_file:\n",
    "        # Analyze structure\n",
    "        analysis = analyzer.analyze_structure(pdb_file)\n",
    "        \n",
    "        if analysis:\n",
    "            print(f\"   ‚úÖ Chains: {len(analysis['chains'])}\")\n",
    "            print(f\"   ‚úÖ Residues: {len(analysis['residues'])}\")\n",
    "            print(f\"   ‚úÖ Atoms: {analysis['atoms']:,}\")\n",
    "            print(f\"   ‚úÖ Ligands: {len(analysis['ligands'])}\")\n",
    "            \n",
    "            if analysis['ligands']:\n",
    "                print(f\"   üìã Ligand details:\")\n",
    "                for ligand in analysis['ligands']:\n",
    "                    print(f\"      - {ligand['name']} (Chain {ligand['chain']}, {ligand['atoms']} atoms)\")\n",
    "            \n",
    "            # Find binding sites\n",
    "            if protein['ligand'] in [lig['name'] for lig in analysis['ligands']]:\n",
    "                binding_sites = analyzer.find_binding_sites(pdb_file, protein['ligand'])\n",
    "                \n",
    "                if binding_sites:\n",
    "                    print(f\"   üéØ Binding site found for {protein['ligand']}:\")\n",
    "                    for site in binding_sites:\n",
    "                        nearby_count = len(site['nearby_residues'])\n",
    "                        print(f\"      - {nearby_count} nearby residues within 5√Ö\")\n",
    "            \n",
    "            # Prepare receptor\n",
    "            receptor_file = os.path.join('structures', f\"{pdb_id.lower()}_receptor.pdb\")\n",
    "            clean_receptor = analyzer.prepare_receptor(pdb_file, receptor_file, \n",
    "                                                     remove_waters=True, remove_ligands=True)\n",
    "            \n",
    "            protein_data[pdb_id] = {\n",
    "                'name': name,\n",
    "                'pdb_file': pdb_file,\n",
    "                'receptor_file': clean_receptor,\n",
    "                'analysis': analysis,\n",
    "                'ligand': protein['ligand']\n",
    "            }\n",
    "        else:\n",
    "            print(f\"   ‚ùå Failed to analyze {pdb_id}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Failed to download {pdb_id}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Processed {len(protein_data)} proteins successfully\")\n",
    "print(f\"‚úÖ Ready for molecular docking experiments\")\n",
    "\n",
    "# ASSESSMENT CHECKPOINT 3.1: Protein Structure Analysis Mastery\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ ASSESSMENT CHECKPOINT 3.1: Protein Structure Analysis\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "assessment.start_section(\"protein_structure_analysis\")\n",
    "\n",
    "# Structure Analysis Concepts Assessment\n",
    "structure_concepts = {\n",
    "    \"pdb_format\": {\n",
    "        \"question\": \"What information is typically stored in a PDB file?\",\n",
    "        \"options\": [\n",
    "            \"a) Only protein sequence data\",\n",
    "            \"b) 3D coordinates, atom types, and experimental metadata\",\n",
    "            \"c) Only ligand structures\",\n",
    "            \"d) Just molecular formulas\"\n",
    "        ],\n",
    "        \"correct\": \"b\",\n",
    "        \"explanation\": \"PDB files contain 3D atomic coordinates, atom types, experimental conditions, and structural metadata for proteins and ligands.\"\n",
    "    },\n",
    "    \"binding_sites\": {\n",
    "        \"question\": \"How are binding sites typically identified in protein structures?\",\n",
    "        \"options\": [\n",
    "            \"a) Random selection of residues\",\n",
    "            \"b) Proximity to co-crystallized ligands or cavity detection algorithms\",\n",
    "            \"c) Only surface residues\",\n",
    "            \"d) Central protein regions\"\n",
    "        ],\n",
    "        \"correct\": \"b\",\n",
    "        \"explanation\": \"Binding sites are identified using co-crystallized ligands or computational cavity detection algorithms that find druggable pockets.\"\n",
    "    },\n",
    "    \"structure_preparation\": {\n",
    "        \"question\": \"Why is protein structure preparation crucial for molecular docking?\",\n",
    "        \"options\": [\n",
    "            \"a) To reduce file size\",\n",
    "            \"b) To remove artifacts, add hydrogens, and optimize for docking\",\n",
    "            \"c) To change protein sequence\",\n",
    "            \"d) To add more ligands\"\n",
    "        ],\n",
    "        \"correct\": \"b\",\n",
    "        \"explanation\": \"Structure preparation removes crystallographic waters, adds missing hydrogens, optimizes side chains, and ensures proper protonation states.\"\n",
    "    },\n",
    "    \"ligand_extraction\": {\n",
    "        \"question\": \"What is the purpose of extracting native ligands from crystal structures?\",\n",
    "        \"options\": [\n",
    "            \"a) To delete them permanently\",\n",
    "            \"b) To use as reference for binding site definition and validation\",\n",
    "            \"c) To reduce computational cost\",\n",
    "            \"d) To simplify the structure\"\n",
    "        ],\n",
    "        \"correct\": \"b\",\n",
    "        \"explanation\": \"Native ligands help define the binding site, validate docking protocols, and serve as positive controls for virtual screening.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Present structure analysis assessment\n",
    "for concept, data in structure_concepts.items():\n",
    "    print(f\"\\nüìö {concept.replace('_', ' ').title()}:\")\n",
    "    print(f\"Q: {data['question']}\")\n",
    "    for option in data['options']:\n",
    "        print(f\"   {option}\")\n",
    "    \n",
    "    user_answer = input(\"\\nYour answer (a/b/c/d): \").lower().strip()\n",
    "    \n",
    "    if user_answer == data['correct']:\n",
    "        print(f\"‚úÖ Correct! {data['explanation']}\")\n",
    "        assessment.record_activity(concept, \"correct\", {\"score\": 1.0})\n",
    "    else:\n",
    "        print(f\"‚ùå Incorrect. {data['explanation']}\")\n",
    "        assessment.record_activity(concept, \"incorrect\", {\"score\": 0.0})\n",
    "\n",
    "# Practical Structure Analysis Assessment\n",
    "print(f\"\\nüõ†Ô∏è Hands-On: Structure Analysis Performance\")\n",
    "print(\"Analyzing your protein structure analysis results:\")\n",
    "\n",
    "proteins_processed = len(protein_data)\n",
    "expected_proteins = len(target_proteins)\n",
    "\n",
    "print(f\"Proteins successfully processed: {proteins_processed}/{expected_proteins}\")\n",
    "\n",
    "if proteins_processed == expected_proteins:\n",
    "    print(\"üåü Excellent! All target proteins processed successfully!\")\n",
    "    assessment.record_activity(\"structure_processing\", \"excellent\", {\n",
    "        \"score\": 1.0, \n",
    "        \"proteins_processed\": proteins_processed,\n",
    "        \"success_rate\": 1.0\n",
    "    })\n",
    "elif proteins_processed >= expected_proteins * 0.7:\n",
    "    print(\"üëç Good! Most proteins processed successfully!\")\n",
    "    assessment.record_activity(\"structure_processing\", \"good\", {\n",
    "        \"score\": 0.8, \n",
    "        \"proteins_processed\": proteins_processed,\n",
    "        \"success_rate\": proteins_processed / expected_proteins\n",
    "    })\n",
    "else:\n",
    "    print(\"üìà Structure processing needs improvement - check network and dependencies\")\n",
    "    assessment.record_activity(\"structure_processing\", \"needs_improvement\", {\n",
    "        \"score\": 0.6, \n",
    "        \"proteins_processed\": proteins_processed,\n",
    "        \"success_rate\": proteins_processed / expected_proteins\n",
    "    })\n",
    "\n",
    "# Binding Site Analysis Assessment\n",
    "binding_sites_found = 0\n",
    "for pdb_id, data in protein_data.items():\n",
    "    if data['analysis'] and data['analysis']['ligands']:\n",
    "        binding_sites_found += 1\n",
    "\n",
    "print(f\"\\nBinding sites identified: {binding_sites_found}/{proteins_processed}\")\n",
    "\n",
    "if binding_sites_found > 0:\n",
    "    print(\"‚úÖ Successfully identified binding sites with ligands!\")\n",
    "    assessment.record_activity(\"binding_site_identification\", \"successful\", {\n",
    "        \"score\": 1.0,\n",
    "        \"sites_found\": binding_sites_found\n",
    "    })\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No binding sites with ligands identified - check structure analysis\")\n",
    "    assessment.record_activity(\"binding_site_identification\", \"incomplete\", {\n",
    "        \"score\": 0.0,\n",
    "        \"sites_found\": 0\n",
    "    })\n",
    "\n",
    "assessment.end_section(\"protein_structure_analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8873d4ed",
   "metadata": {},
   "source": [
    "## Section 2: Molecular Docking Implementation (1.5 hours)\n",
    "\n",
    "**Objective:** Implement molecular docking using AutoDock Vina and develop scoring analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5ee47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìã Section 1 Completion Assessment: Protein Structure Analysis & Preparation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã SECTION 1 COMPLETION ASSESSMENT\")\n",
    "print(\"üß¨ Protein Structure Analysis & Preparation Mastery\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Assessment for Section 1: Protein Structure Analysis & Preparation\n",
    "section1_concepts = [\n",
    "    \"Protein structure hierarchy and organization\",\n",
    "    \"PDB file format and structure data interpretation\", \n",
    "    \"Binding site identification and characterization\",\n",
    "    \"Protein preparation for molecular docking\",\n",
    "    \"Structure validation and quality assessment\",\n",
    "    \"Druggability assessment and pocket analysis\",\n",
    "    \"Structural alignment and comparison techniques\"\n",
    "]\n",
    "\n",
    "section1_activities = [\n",
    "    \"Downloaded and analyzed protein structures from PDB\",\n",
    "    \"Implemented protein structure parsing with BioPython\",\n",
    "    \"Identified and characterized binding sites\",\n",
    "    \"Performed protein structure preparation workflows\",\n",
    "    \"Conducted structure quality validation\",\n",
    "    \"Analyzed druggability of identified binding pockets\",\n",
    "    \"Implemented structural comparison and alignment\"\n",
    "]\n",
    "\n",
    "# Create interactive assessment widget for Section 1\n",
    "section1_widget = create_widget(\n",
    "    day3_assessment,\n",
    "    \"Section 1: Protein Structure Analysis & Preparation\",\n",
    "    section1_concepts,\n",
    "    section1_activities,\n",
    "    time_target=90,  # 1.5 hours\n",
    "    section_type=\"completion_assessment\"\n",
    ")\n",
    "\n",
    "print(\"üéØ Section 1 Completion Assessment Ready!\")\n",
    "print(\"üëâ Please evaluate your understanding and practical completion:\")\n",
    "section1_widget.display()\n",
    "\n",
    "# Record section completion\n",
    "day3_assessment.record_activity(\"section1_completion\", {\n",
    "    \"section\": \"protein_structure_analysis\",\n",
    "    \"concepts_covered\": len(section1_concepts),\n",
    "    \"activities_completed\": len(section1_activities),\n",
    "    \"time_target_minutes\": 90,\n",
    "    \"focus_areas\": [\"structure_analysis\", \"binding_sites\", \"preparation\", \"validation\"],\n",
    "    \"specialization_alignment\": selected_track\n",
    "})\n",
    "\n",
    "print(\"\\n‚úÖ Section 1 assessment completed!\")\n",
    "print(\"üöÄ Ready to proceed to Section 2: Molecular Docking Implementation\")\n",
    "print(\"\\n\" + \"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3a3082",
   "metadata": {},
   "source": [
    "## Section 2: Molecular Docking Implementation (1.5 hours)\n",
    "\n",
    "**Objective:** Master AutoDock Vina integration, binding pose analysis, and docking workflow optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27461d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Molecular Docking Engine Implementation\n",
    "import subprocess\n",
    "import tempfile\n",
    "import json\n",
    "from io import StringIO\n",
    "\n",
    "class MolecularDockingEngine:\n",
    "    \"\"\"Comprehensive molecular docking implementation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vina_available = self.check_vina_installation()\n",
    "        self.obabel_available = self.check_obabel_installation()\n",
    "        \n",
    "    def check_vina_installation(self):\n",
    "        \"\"\"Check if AutoDock Vina is available\"\"\"\n",
    "        try:\n",
    "            result = subprocess.run(['vina', '--help'], capture_output=True, text=True)\n",
    "            return result.returncode == 0\n",
    "        except FileNotFoundError:\n",
    "            print(\"‚ö†Ô∏è  AutoDock Vina not found. Some features will be simulated.\")\n",
    "            return False\n",
    "    \n",
    "    def check_obabel_installation(self):\n",
    "        \"\"\"Check if Open Babel is available\"\"\"\n",
    "        try:\n",
    "            result = subprocess.run(['obabel', '-H'], capture_output=True, text=True)\n",
    "            return result.returncode == 0\n",
    "        except FileNotFoundError:\n",
    "            print(\"‚ö†Ô∏è  Open Babel not found. Using RDKit for conversions.\")\n",
    "            return False\n",
    "    \n",
    "    def prepare_ligand(self, smiles, output_file, ligand_name=\"UNL\"):\n",
    "        \"\"\"Prepare ligand from SMILES for docking\"\"\"\n",
    "        try:\n",
    "            # Create molecule from SMILES\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                print(f\"‚ùå Invalid SMILES: {smiles}\")\n",
    "                return None\n",
    "            \n",
    "            # Add hydrogens\n",
    "            mol = Chem.AddHs(mol)\n",
    "            \n",
    "            # Generate 3D coordinates\n",
    "            AllChem.EmbedMolecule(mol, randomSeed=42)\n",
    "            AllChem.MMFFOptimizeMolecule(mol)\n",
    "            \n",
    "            # Save as SDF first\n",
    "            sdf_file = output_file.replace('.pdbqt', '.sdf')\n",
    "            writer = Chem.SDWriter(sdf_file)\n",
    "            writer.write(mol)\n",
    "            writer.close()\n",
    "            \n",
    "            # Convert to PDBQT using RDKit (simplified)\n",
    "            pdb_block = Chem.MolToPDBBlock(mol)\n",
    "            \n",
    "            # Create simplified PDBQT content\n",
    "            pdbqt_content = self.convert_pdb_to_pdbqt_simple(pdb_block, ligand_name)\n",
    "            \n",
    "            with open(output_file, 'w') as f:\n",
    "                f.write(pdbqt_content)\n",
    "            \n",
    "            print(f\"‚úÖ Ligand prepared: {output_file}\")\n",
    "            return output_file\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error preparing ligand: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def convert_pdb_to_pdbqt_simple(self, pdb_block, ligand_name=\"UNL\"):\n",
    "        \"\"\"Simple PDB to PDBQT conversion (simplified)\"\"\"\n",
    "        lines = pdb_block.split('\\n')\n",
    "        pdbqt_lines = []\n",
    "        \n",
    "        for line in lines:\n",
    "            if line.startswith('HETATM') or line.startswith('ATOM'):\n",
    "                # Simple atomic charge assignment (very basic)\n",
    "                atom_type = line[76:78].strip()\n",
    "                \n",
    "                # Basic charge assignment\n",
    "                charge_map = {'C': 0.0, 'N': -0.1, 'O': -0.2, 'S': 0.0, 'P': 0.0, 'H': 0.1}\n",
    "                charge = charge_map.get(atom_type, 0.0)\n",
    "                \n",
    "                # Modify line for PDBQT format\n",
    "                new_line = line[:66] + f\"{charge:6.3f}\" + line[72:]\n",
    "                pdbqt_lines.append(new_line)\n",
    "        \n",
    "        # Add ROOT and ENDROOT for rotatable bonds (simplified)\n",
    "        if pdbqt_lines:\n",
    "            pdbqt_content = \"ROOT\\n\" + \"\\n\".join(pdbqt_lines) + \"\\nENDROOT\\n\"\n",
    "        else:\n",
    "            pdbqt_content = \"\"\n",
    "            \n",
    "        return pdbqt_content\n",
    "    \n",
    "    def prepare_receptor_pdbqt(self, pdb_file, output_file):\n",
    "        \"\"\"Prepare receptor PDBQT file\"\"\"\n",
    "        try:\n",
    "            # For this implementation, we'll create a simplified PDBQT\n",
    "            # In practice, you'd use MGLTools' prepare_receptor4.py\n",
    "            \n",
    "            with open(pdb_file, 'r') as f:\n",
    "                pdb_content = f.read()\n",
    "            \n",
    "            # Simple conversion - keep only ATOM records\n",
    "            lines = pdb_content.split('\\n')\n",
    "            pdbqt_lines = []\n",
    "            \n",
    "            for line in lines:\n",
    "                if line.startswith('ATOM'):\n",
    "                    # Basic PDBQT format (simplified)\n",
    "                    atom_type = line[76:78].strip()\n",
    "                    charge = 0.0  # Simplified\n",
    "                    \n",
    "                    new_line = line[:66] + f\"{charge:6.3f}\" + line[72:]\n",
    "                    pdbqt_lines.append(new_line)\n",
    "            \n",
    "            with open(output_file, 'w') as f:\n",
    "                f.write(\"\\n\".join(pdbqt_lines))\n",
    "            \n",
    "            print(f\"‚úÖ Receptor PDBQT prepared: {output_file}\")\n",
    "            return output_file\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error preparing receptor PDBQT: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def calculate_binding_site_center(self, pdb_file, ligand_name):\n",
    "        \"\"\"Calculate binding site center from co-crystallized ligand\"\"\"\n",
    "        try:\n",
    "            structure = analyzer.parser.get_structure('protein', pdb_file)\n",
    "            \n",
    "            ligand_atoms = []\n",
    "            for model in structure:\n",
    "                for chain in model:\n",
    "                    for residue in chain:\n",
    "                        if residue.get_resname() == ligand_name:\n",
    "                            for atom in residue:\n",
    "                                ligand_atoms.append(atom.get_coord())\n",
    "            \n",
    "            if ligand_atoms:\n",
    "                center = np.mean(ligand_atoms, axis=0)\n",
    "                return {'x': float(center[0]), 'y': float(center[1]), 'z': float(center[2])}\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è  Ligand {ligand_name} not found, using geometric center\")\n",
    "                \n",
    "                # Use geometric center of all atoms\n",
    "                all_atoms = []\n",
    "                for model in structure:\n",
    "                    for chain in model:\n",
    "                        for residue in chain:\n",
    "                            if residue.get_id()[0] == ' ':  # Protein atoms only\n",
    "                                for atom in residue:\n",
    "                                    all_atoms.append(atom.get_coord())\n",
    "                \n",
    "                if all_atoms:\n",
    "                    center = np.mean(all_atoms, axis=0)\n",
    "                    return {'x': float(center[0]), 'y': float(center[1]), 'z': float(center[2])}\n",
    "                \n",
    "            return {'x': 0.0, 'y': 0.0, 'z': 0.0}\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error calculating binding site center: {e}\")\n",
    "            return {'x': 0.0, 'y': 0.0, 'z': 0.0}\n",
    "    \n",
    "    def run_vina_docking(self, receptor_pdbqt, ligand_pdbqt, center, box_size=20, exhaustiveness=8):\n",
    "        \"\"\"Run AutoDock Vina docking\"\"\"\n",
    "        try:\n",
    "            if not self.vina_available:\n",
    "                # Simulate docking results\n",
    "                return self.simulate_docking_results(receptor_pdbqt, ligand_pdbqt, center)\n",
    "            \n",
    "            # Create Vina configuration\n",
    "            config_content = f\"\"\"receptor = {receptor_pdbqt}\n",
    "ligand = {ligand_pdbqt}\n",
    "\n",
    "center_x = {center['x']}\n",
    "center_y = {center['y']}\n",
    "center_z = {center['z']}\n",
    "\n",
    "size_x = {box_size}\n",
    "size_y = {box_size}\n",
    "size_z = {box_size}\n",
    "\n",
    "out = {ligand_pdbqt.replace('.pdbqt', '_out.pdbqt')}\n",
    "log = {ligand_pdbqt.replace('.pdbqt', '_log.txt')}\n",
    "\n",
    "exhaustiveness = {exhaustiveness}\n",
    "num_modes = 9\n",
    "energy_range = 3\n",
    "\"\"\"\n",
    "            \n",
    "            config_file = ligand_pdbqt.replace('.pdbqt', '_config.txt')\n",
    "            with open(config_file, 'w') as f:\n",
    "                f.write(config_content)\n",
    "            \n",
    "            # Run Vina\n",
    "            cmd = ['vina', '--config', config_file]\n",
    "            result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "            \n",
    "            if result.returncode == 0:\n",
    "                # Parse results\n",
    "                log_file = ligand_pdbqt.replace('.pdbqt', '_log.txt')\n",
    "                return self.parse_vina_results(log_file)\n",
    "            else:\n",
    "                print(f\"‚ùå Vina failed: {result.stderr}\")\n",
    "                return self.simulate_docking_results(receptor_pdbqt, ligand_pdbqt, center)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Docking error: {e}\")\n",
    "            return self.simulate_docking_results(receptor_pdbqt, ligand_pdbqt, center)\n",
    "    \n",
    "    def simulate_docking_results(self, receptor_pdbqt, ligand_pdbqt, center):\n",
    "        \"\"\"Simulate docking results when Vina is not available\"\"\"\n",
    "        # Generate realistic-looking docking scores\n",
    "        np.random.seed(42)  # For reproducibility\n",
    "        \n",
    "        num_poses = 9\n",
    "        base_score = np.random.uniform(-12, -6)\n",
    "        \n",
    "        results = []\n",
    "        for i in range(num_poses):\n",
    "            score = base_score + i * 0.5 + np.random.normal(0, 0.3)\n",
    "            rmsd_lb = np.random.uniform(0, 2)\n",
    "            rmsd_ub = rmsd_lb + np.random.uniform(0, 1)\n",
    "            \n",
    "            results.append({\n",
    "                'mode': i + 1,\n",
    "                'affinity': score,\n",
    "                'rmsd_lb': rmsd_lb,\n",
    "                'rmsd_ub': rmsd_ub\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def parse_vina_results(self, log_file):\n",
    "        \"\"\"Parse Vina docking results from log file\"\"\"\n",
    "        try:\n",
    "            with open(log_file, 'r') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            results = []\n",
    "            lines = content.split('\\n')\n",
    "            \n",
    "            for line in lines:\n",
    "                if line.strip() and not line.startswith('#') and len(line.split()) >= 4:\n",
    "                    parts = line.split()\n",
    "                    if len(parts) >= 4 and parts[0].isdigit():\n",
    "                        results.append({\n",
    "                            'mode': int(parts[0]),\n",
    "                            'affinity': float(parts[1]),\n",
    "                            'rmsd_lb': float(parts[2]),\n",
    "                            'rmsd_ub': float(parts[3])\n",
    "                        })\n",
    "            \n",
    "            return results\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error parsing Vina results: {e}\")\n",
    "            return []\n",
    "\n",
    "# Initialize docking engine\n",
    "docking_engine = MolecularDockingEngine()\n",
    "print(\"‚úÖ Molecular Docking Engine initialized\")\n",
    "print(f\"   Vina available: {docking_engine.vina_available}\")\n",
    "print(f\"   Open Babel available: {docking_engine.obabel_available}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f32d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test ligands for docking experiments\n",
    "test_ligands = [\n",
    "    {\n",
    "        'name': 'Aspirin',\n",
    "        'smiles': 'CC(=O)OC1=CC=CC=C1C(=O)O',\n",
    "        'target': 'General anti-inflammatory'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Ibuprofen', \n",
    "        'smiles': 'CC(C)CC1=CC=C(C=C1)C(C)C(=O)O',\n",
    "        'target': 'COX inhibitor'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Caffeine',\n",
    "        'smiles': 'CN1C=NC2=C1C(=O)N(C(=O)N2C)C',\n",
    "        'target': 'Adenosine receptor antagonist'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Ritonavir-like',\n",
    "        'smiles': 'CC(C)C1=NC(=CS1)CN(C)C(=O)NC(CC2=CC=CC=C2)C(=O)NC(CC(C)C)CC(=O)O',\n",
    "        'target': 'HIV protease inhibitor'\n",
    "    },\n",
    "    {\n",
    "        'name': 'Oseltamivir-like',\n",
    "        'smiles': 'CCOC(=O)C1=CC(=CC=C1)NC(=O)C2CC(CC(C2NC(=O)C)N)C(=O)O',\n",
    "        'target': 'Neuraminidase inhibitor'\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üß™ Preparing Test Ligands for Docking:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Prepare ligands\n",
    "ligand_files = {}\n",
    "\n",
    "for ligand in test_ligands:\n",
    "    ligand_name = ligand['name'].replace(' ', '_').replace('-', '_')\n",
    "    output_file = os.path.join('ligands', f\"{ligand_name}.pdbqt\")\n",
    "    \n",
    "    print(f\"üìù Preparing {ligand['name']}...\")\n",
    "    \n",
    "    # Prepare ligand file\n",
    "    ligand_file = docking_engine.prepare_ligand(\n",
    "        ligand['smiles'], \n",
    "        output_file, \n",
    "        ligand_name\n",
    "    )\n",
    "    \n",
    "    if ligand_file:\n",
    "        ligand_files[ligand['name']] = {\n",
    "            'file': ligand_file,\n",
    "            'smiles': ligand['smiles'],\n",
    "            'target': ligand['target']\n",
    "        }\n",
    "        print(f\"   ‚úÖ {ligand['name']} prepared\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå Failed to prepare {ligand['name']}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Prepared {len(ligand_files)} ligands for docking\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f835a40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive docking experiments\n",
    "\n",
    "print(\"üéØ Running Comprehensive Docking Experiments:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "docking_results = {}\n",
    "\n",
    "# Prepare receptor PDBQT files\n",
    "receptor_pdbqts = {}\n",
    "for pdb_id, protein_info in protein_data.items():\n",
    "    if protein_info['receptor_file']:\n",
    "        receptor_pdbqt = os.path.join('structures', f\"{pdb_id.lower()}_receptor.pdbqt\")\n",
    "        pdbqt_file = docking_engine.prepare_receptor_pdbqt(\n",
    "            protein_info['receptor_file'], \n",
    "            receptor_pdbqt\n",
    "        )\n",
    "        \n",
    "        if pdbqt_file:\n",
    "            receptor_pdbqts[pdb_id] = pdbqt_file\n",
    "\n",
    "# Run docking for each protein-ligand combination\n",
    "for pdb_id, protein_info in protein_data.items():\n",
    "    if pdb_id not in receptor_pdbqts:\n",
    "        continue\n",
    "        \n",
    "    print(f\"\\nüß¨ Docking to {protein_info['name']} ({pdb_id}):\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    # Calculate binding site center\n",
    "    center = docking_engine.calculate_binding_site_center(\n",
    "        protein_info['pdb_file'], \n",
    "        protein_info['ligand']\n",
    "    )\n",
    "    \n",
    "    print(f\"   üìç Binding site center: ({center['x']:.2f}, {center['y']:.2f}, {center['z']:.2f})\")\n",
    "    \n",
    "    protein_results = {}\n",
    "    \n",
    "    for ligand_name, ligand_info in ligand_files.items():\n",
    "        print(f\"   üî¨ Docking {ligand_name}...\")\n",
    "        \n",
    "        # Run docking\n",
    "        results = docking_engine.run_vina_docking(\n",
    "            receptor_pdbqts[pdb_id],\n",
    "            ligand_info['file'],\n",
    "            center,\n",
    "            box_size=20,\n",
    "            exhaustiveness=8\n",
    "        )\n",
    "        \n",
    "        if results:\n",
    "            best_score = min([r['affinity'] for r in results])\n",
    "            print(f\"      ‚úÖ Best score: {best_score:.2f} kcal/mol\")\n",
    "            \n",
    "            protein_results[ligand_name] = {\n",
    "                'results': results,\n",
    "                'best_score': best_score,\n",
    "                'ligand_info': ligand_info\n",
    "            }\n",
    "        else:\n",
    "            print(f\"      ‚ùå Docking failed\")\n",
    "    \n",
    "    docking_results[pdb_id] = {\n",
    "        'protein_info': protein_info,\n",
    "        'binding_center': center,\n",
    "        'ligand_results': protein_results\n",
    "    }\n",
    "\n",
    "print(\"\\n‚úÖ Completed docking experiments\")\n",
    "print(f\"‚úÖ Tested {len(ligand_files)} ligands against {len(docking_results)} proteins\")\n",
    "\n",
    "# ASSESSMENT CHECKPOINT 3.2: Molecular Docking Implementation\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ ASSESSMENT CHECKPOINT 3.2: Molecular Docking Mastery\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "assessment.start_section(\"molecular_docking\")\n",
    "\n",
    "# Molecular Docking Concepts Assessment\n",
    "docking_concepts = {\n",
    "    \"search_algorithm\": {\n",
    "        \"question\": \"What is the primary challenge in molecular docking?\",\n",
    "        \"options\": [\n",
    "            \"a) Converting file formats\",\n",
    "            \"b) Efficiently searching the conformational space for optimal binding poses\",\n",
    "            \"c) Visualizing molecules\",\n",
    "            \"d) Calculating molecular weight\"\n",
    "        ],\n",
    "        \"correct\": \"b\",\n",
    "        \"explanation\": \"The main challenge is efficiently exploring the vast conformational space to find the optimal binding pose between ligand and receptor.\"\n",
    "    },\n",
    "    \"scoring_function\": {\n",
    "        \"question\": \"What does a docking scoring function estimate?\",\n",
    "        \"options\": [\n",
    "            \"a) Molecular weight\",\n",
    "            \"b) Binding affinity between ligand and receptor\",\n",
    "            \"c) Number of atoms\",\n",
    "            \"d) Chemical formula\"\n",
    "        ],\n",
    "        \"correct\": \"b\",\n",
    "        \"explanation\": \"Scoring functions estimate the binding affinity (typically in kcal/mol) to rank different binding poses and compounds.\"\n",
    "    },\n",
    "    \"vina_algorithm\": {\n",
    "        \"question\": \"What makes AutoDock Vina particularly effective for molecular docking?\",\n",
    "        \"options\": [\n",
    "            \"a) It only uses simple force fields\",\n",
    "            \"b) Combines gradient optimization with random sampling and machine learning\",\n",
    "            \"c) It's the fastest algorithm available\",\n",
    "            \"d) It only works with small molecules\"\n",
    "        ],\n",
    "        \"correct\": \"b\",\n",
    "        \"explanation\": \"Vina combines multiple optimization strategies including gradient-based optimization, random sampling, and empirical scoring functions trained on experimental data.\"\n",
    "    },\n",
    "    \"pose_analysis\": {\n",
    "        \"question\": \"What does RMSD (Root Mean Square Deviation) measure in docking results?\",\n",
    "        \"options\": [\n",
    "            \"a) Binding energy\",\n",
    "            \"b) Molecular weight difference\",\n",
    "            \"c) Spatial difference between poses or crystal structure\",\n",
    "            \"d) Number of bonds\"\n",
    "        ],\n",
    "        \"correct\": \"c\",\n",
    "        \"explanation\": \"RMSD measures the spatial deviation between predicted poses or between a predicted pose and the crystal structure reference.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Present docking concepts assessment\n",
    "for concept, data in docking_concepts.items():\n",
    "    print(f\"\\nüìö {concept.replace('_', ' ').title()}:\")\n",
    "    print(f\"Q: {data['question']}\")\n",
    "    for option in data['options']:\n",
    "        print(f\"   {option}\")\n",
    "    \n",
    "    user_answer = input(\"\\nYour answer (a/b/c/d): \").lower().strip()\n",
    "    \n",
    "    if user_answer == data['correct']:\n",
    "        print(f\"‚úÖ Correct! {data['explanation']}\")\n",
    "        assessment.record_activity(concept, \"correct\", {\"score\": 1.0})\n",
    "    else:\n",
    "        print(f\"‚ùå Incorrect. {data['explanation']}\")\n",
    "        assessment.record_activity(concept, \"incorrect\", {\"score\": 0.0})\n",
    "\n",
    "# Practical Docking Implementation Assessment\n",
    "print(f\"\\nüõ†Ô∏è Hands-On: Docking Implementation Performance\")\n",
    "\n",
    "# Evaluate docking experiment success\n",
    "total_experiments = len(protein_data) * len(test_ligands)\n",
    "successful_dockings = 0\n",
    "total_poses = 0\n",
    "\n",
    "for pdb_id, protein_results in docking_results.items():\n",
    "    for ligand_name, ligand_result in protein_results.get('ligand_results', {}).items():\n",
    "        if ligand_result.get('results'):\n",
    "            successful_dockings += 1\n",
    "            total_poses += len(ligand_result['results'])\n",
    "\n",
    "success_rate = successful_dockings / total_experiments if total_experiments > 0 else 0\n",
    "\n",
    "print(f\"Docking experiments completed: {successful_dockings}/{total_experiments}\")\n",
    "print(f\"Success rate: {success_rate:.1%}\")\n",
    "print(f\"Total poses generated: {total_poses}\")\n",
    "\n",
    "if success_rate >= 0.8:\n",
    "    print(\"üåü Excellent docking implementation!\")\n",
    "    assessment.record_activity(\"docking_implementation\", \"excellent\", {\n",
    "        \"score\": 1.0,\n",
    "        \"success_rate\": success_rate,\n",
    "        \"experiments_completed\": successful_dockings,\n",
    "        \"total_poses\": total_poses\n",
    "    })\n",
    "elif success_rate >= 0.6:\n",
    "    print(\"üëç Good docking implementation!\")\n",
    "    assessment.record_activity(\"docking_implementation\", \"good\", {\n",
    "        \"score\": 0.8,\n",
    "        \"success_rate\": success_rate,\n",
    "        \"experiments_completed\": successful_dockings,\n",
    "        \"total_poses\": total_poses\n",
    "    })\n",
    "else:\n",
    "    print(\"üìà Docking implementation needs improvement\")\n",
    "    assessment.record_activity(\"docking_implementation\", \"needs_improvement\", {\n",
    "        \"score\": 0.6,\n",
    "        \"success_rate\": success_rate,\n",
    "        \"experiments_completed\": successful_dockings,\n",
    "        \"total_poses\": total_poses\n",
    "    })\n",
    "\n",
    "# Evaluate binding affinity predictions\n",
    "best_affinities = []\n",
    "for pdb_id, protein_results in docking_results.items():\n",
    "    for ligand_name, ligand_result in protein_results.get('ligand_results', {}).items():\n",
    "        if ligand_result.get('results'):\n",
    "            best_score = min([pose['affinity'] for pose in ligand_result['results']])\n",
    "            best_affinities.append(best_score)\n",
    "\n",
    "if best_affinities:\n",
    "    avg_affinity = np.mean(best_affinities)\n",
    "    min_affinity = np.min(best_affinities)\n",
    "    \n",
    "    print(f\"\\nBinding Affinity Analysis:\")\n",
    "    print(f\"   Average best affinity: {avg_affinity:.2f} kcal/mol\")\n",
    "    print(f\"   Best affinity found: {min_affinity:.2f} kcal/mol\")\n",
    "    \n",
    "    if min_affinity < -8.0:  # Strong binding\n",
    "        print(\"‚úÖ Identified compounds with strong binding potential!\")\n",
    "        assessment.record_activity(\"affinity_analysis\", \"strong_binders\", {\n",
    "            \"score\": 1.0,\n",
    "            \"best_affinity\": min_affinity,\n",
    "            \"average_affinity\": avg_affinity\n",
    "        })\n",
    "    elif min_affinity < -6.0:  # Moderate binding\n",
    "        print(\"üëç Found compounds with moderate binding affinity!\")\n",
    "        assessment.record_activity(\"affinity_analysis\", \"moderate_binders\", {\n",
    "            \"score\": 0.8,\n",
    "            \"best_affinity\": min_affinity,\n",
    "            \"average_affinity\": avg_affinity\n",
    "        })\n",
    "    else:\n",
    "        print(\"üìä Binding affinities detected - consider more diverse ligand library\")\n",
    "        assessment.record_activity(\"affinity_analysis\", \"weak_binders\", {\n",
    "            \"score\": 0.6,\n",
    "            \"best_affinity\": min_affinity,\n",
    "            \"average_affinity\": avg_affinity\n",
    "        })\n",
    "\n",
    "assessment.end_section(\"molecular_docking\")\n",
    "\n",
    "# üéØ SECTION 2 COMPLETION ASSESSMENT\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéì SECTION 2 COMPLETION ASSESSMENT: Molecular Docking Implementation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Section 2: Key concepts to evaluate\n",
    "section2_concepts = [\n",
    "    \"AutoDock Vina integration and configuration\",\n",
    "    \"PDBQT file format and preparation workflows\", \n",
    "    \"Binding site definition and search space optimization\",\n",
    "    \"Docking score interpretation and pose ranking\",\n",
    "    \"RMSD analysis and pose validation\",\n",
    "    \"Exhaustiveness parameters and computational efficiency\",\n",
    "    \"Docking result visualization and analysis\"\n",
    "]\n",
    "\n",
    "# Section 2: Hands-on activities completed\n",
    "section2_activities = [\n",
    "    \"Implemented MolecularDockingEngine class\",\n",
    "    \"Set up AutoDock Vina integration and file handling\",\n",
    "    \"Created ligand preparation workflows (SMILES to PDBQT)\",\n",
    "    \"Performed systematic docking experiments on test compounds\",\n",
    "    \"Analyzed binding poses and calculated RMSD values\",\n",
    "    \"Optimized docking parameters for target proteins\",\n",
    "    \"Evaluated binding affinities and ranked results\"\n",
    "]\n",
    "\n",
    "# Create interactive assessment widget for Section 2\n",
    "section2_widget = create_widget(\n",
    "    day3_assessment,\n",
    "    \"Section 2: Molecular Docking Implementation\",\n",
    "    section2_concepts,\n",
    "    section2_activities,\n",
    "    time_target=90,  # 1.5 hours\n",
    "    section_type=\"completion_assessment\"\n",
    ")\n",
    "\n",
    "print(\"üéØ Section 2 Completion Assessment Ready!\")\n",
    "print(\"üëâ Please evaluate your understanding and practical completion:\")\n",
    "section2_widget.display()\n",
    "\n",
    "# Record section completion\n",
    "day3_assessment.record_activity(\"section2_completion\", {\n",
    "    \"section\": \"molecular_docking_implementation\",\n",
    "    \"concepts_covered\": len(section2_concepts),\n",
    "    \"activities_completed\": len(section2_activities),\n",
    "    \"time_target_minutes\": 90,\n",
    "    \"focus_areas\": [\"autodock_vina\", \"docking_workflows\", \"pose_analysis\", \"result_interpretation\"],\n",
    "    \"specialization_alignment\": selected_track\n",
    "})\n",
    "\n",
    "print(\"\\n‚úÖ Section 2 assessment completed!\")\n",
    "print(\"üöÄ Ready to proceed to Section 3: Virtual Screening Pipeline\")\n",
    "print(\"\\n\" + \"-\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911961bf",
   "metadata": {},
   "source": [
    "## Section 3: Virtual Screening Pipeline (1.5 hours)\n",
    "\n",
    "**Objective:** Build automated high-throughput virtual screening workflows with filtering and ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaaa815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Virtual Screening Pipeline Implementation\n",
    "import concurrent.futures\n",
    "from itertools import islice\n",
    "import time\n",
    "\n",
    "class VirtualScreeningPipeline:\n",
    "    \"\"\"High-throughput virtual screening pipeline\"\"\"\n",
    "    \n",
    "    def __init__(self, docking_engine):\n",
    "        self.docking_engine = docking_engine\n",
    "        self.filters = []\n",
    "        self.screening_results = []\n",
    "        \n",
    "    def add_filter(self, filter_func, name):\n",
    "        \"\"\"Add molecular filter to pipeline\"\"\"\n",
    "        self.filters.append({'function': filter_func, 'name': name})\n",
    "    \n",
    "    def apply_filters(self, smiles_list):\n",
    "        \"\"\"Apply all filters to compound list\"\"\"\n",
    "        filtered_compounds = []\n",
    "        filter_stats = {}\n",
    "        \n",
    "        print(f\"üîç Applying {len(self.filters)} filters to {len(smiles_list)} compounds...\")\n",
    "        \n",
    "        for smiles in smiles_list:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                continue\n",
    "                \n",
    "            passed_all = True\n",
    "            \n",
    "            for filter_info in self.filters:\n",
    "                filter_func = filter_info['function']\n",
    "                filter_name = filter_info['name']\n",
    "                \n",
    "                if not filter_func(mol):\n",
    "                    passed_all = False\n",
    "                    filter_stats[filter_name] = filter_stats.get(filter_name, 0) + 1\n",
    "                    break\n",
    "            \n",
    "            if passed_all:\n",
    "                filtered_compounds.append(smiles)\n",
    "        \n",
    "        print(f\"   ‚úÖ {len(filtered_compounds)} compounds passed all filters\")\n",
    "        \n",
    "        if filter_stats:\n",
    "            print(\"   üìã Filter rejection statistics:\")\n",
    "            for filter_name, count in filter_stats.items():\n",
    "                print(f\"      - {filter_name}: {count} compounds rejected\")\n",
    "        \n",
    "        return filtered_compounds\n",
    "    \n",
    "    def parallel_docking(self, receptor_pdbqt, ligand_smiles_list, center, \n",
    "                        max_workers=4, chunk_size=10):\n",
    "        \"\"\"Run parallel docking for virtual screening\"\"\"\n",
    "        \n",
    "        def dock_ligand_batch(smiles_batch):\n",
    "            \"\"\"Dock a batch of ligands\"\"\"\n",
    "            batch_results = []\n",
    "            \n",
    "            for i, smiles in enumerate(smiles_batch):\n",
    "                try:\n",
    "                    # Prepare ligand\n",
    "                    ligand_name = f\"ligand_{len(self.screening_results) + len(batch_results)}\"\n",
    "                    ligand_file = os.path.join('ligands', f\"{ligand_name}.pdbqt\")\n",
    "                    \n",
    "                    prepared_ligand = self.docking_engine.prepare_ligand(\n",
    "                        smiles, ligand_file, ligand_name\n",
    "                    )\n",
    "                    \n",
    "                    if prepared_ligand:\n",
    "                        # Run docking\n",
    "                        docking_results = self.docking_engine.run_vina_docking(\n",
    "                            receptor_pdbqt, prepared_ligand, center, \n",
    "                            box_size=20, exhaustiveness=4  # Reduced for speed\n",
    "                        )\n",
    "                        \n",
    "                        if docking_results:\n",
    "                            best_score = min([r['affinity'] for r in docking_results])\n",
    "                            \n",
    "                            batch_results.append({\n",
    "                                'smiles': smiles,\n",
    "                                'ligand_name': ligand_name,\n",
    "                                'best_score': best_score,\n",
    "                                'all_poses': docking_results,\n",
    "                                'status': 'success'\n",
    "                            })\n",
    "                        else:\n",
    "                            batch_results.append({\n",
    "                                'smiles': smiles,\n",
    "                                'ligand_name': ligand_name,\n",
    "                                'best_score': 0.0,\n",
    "                                'all_poses': [],\n",
    "                                'status': 'docking_failed'\n",
    "                            })\n",
    "                    else:\n",
    "                        batch_results.append({\n",
    "                            'smiles': smiles,\n",
    "                            'ligand_name': ligand_name,\n",
    "                            'best_score': 0.0,\n",
    "                            'all_poses': [],\n",
    "                            'status': 'preparation_failed'\n",
    "                        })\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    batch_results.append({\n",
    "                        'smiles': smiles,\n",
    "                        'ligand_name': f\"ligand_{len(self.screening_results) + len(batch_results)}\",\n",
    "                        'best_score': 0.0,\n",
    "                        'all_poses': [],\n",
    "                        'status': f'error: {str(e)}'\n",
    "                    })\n",
    "            \n",
    "            return batch_results\n",
    "        \n",
    "        # Split ligands into chunks\n",
    "        ligand_chunks = [ligand_smiles_list[i:i + chunk_size] \n",
    "                        for i in range(0, len(ligand_smiles_list), chunk_size)]\n",
    "        \n",
    "        print(f\"üî¨ Running parallel docking on {len(ligand_smiles_list)} compounds...\")\n",
    "        print(f\"   Workers: {max_workers}, Chunk size: {chunk_size}\")\n",
    "        \n",
    "        all_results = []\n",
    "        \n",
    "        # Use ThreadPoolExecutor for parallel processing\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            # Submit all chunks\n",
    "            future_to_chunk = {executor.submit(dock_ligand_batch, chunk): i \n",
    "                             for i, chunk in enumerate(ligand_chunks)}\n",
    "            \n",
    "            # Collect results as they complete\n",
    "            for future in concurrent.futures.as_completed(future_to_chunk):\n",
    "                chunk_idx = future_to_chunk[future]\n",
    "                try:\n",
    "                    batch_results = future.result()\n",
    "                    all_results.extend(batch_results)\n",
    "                    print(f\"   ‚úÖ Completed chunk {chunk_idx + 1}/{len(ligand_chunks)} ({len(batch_results)} compounds)\")\n",
    "                except Exception as exc:\n",
    "                    print(f\"   ‚ùå Chunk {chunk_idx + 1} generated an exception: {exc}\")\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def rank_compounds(self, screening_results, ranking_method='affinity'):\n",
    "        \"\"\"Rank compounds based on docking scores and other criteria\"\"\"\n",
    "        \n",
    "        if ranking_method == 'affinity':\n",
    "            # Simple ranking by best affinity score\n",
    "            ranked = sorted(screening_results, \n",
    "                          key=lambda x: x['best_score'], \n",
    "                          reverse=False)  # Lower (more negative) is better\n",
    "            \n",
    "        elif ranking_method == 'composite':\n",
    "            # Composite scoring with multiple factors\n",
    "            scored_results = []\n",
    "            \n",
    "            for result in screening_results:\n",
    "                if result['status'] == 'success':\n",
    "                    mol = Chem.MolFromSmiles(result['smiles'])\n",
    "                    if mol:\n",
    "                        # Calculate molecular properties\n",
    "                        mw = Descriptors.MolWt(mol)\n",
    "                        logp = Descriptors.MolLogP(mol)\n",
    "                        hbd = Descriptors.NumHDonors(mol)\n",
    "                        hba = Descriptors.NumHAcceptors(mol)\n",
    "                        rotatable = Descriptors.NumRotatableBonds(mol)\n",
    "                        \n",
    "                        # Lipinski's Rule of Five scoring\n",
    "                        lipinski_score = 0\n",
    "                        if mw <= 500: lipinski_score += 1\n",
    "                        if logp <= 5: lipinski_score += 1\n",
    "                        if hbd <= 5: lipinski_score += 1\n",
    "                        if hba <= 10: lipinski_score += 1\n",
    "                        \n",
    "                        # Composite score (normalized)\n",
    "                        affinity_score = max(0, (result['best_score'] + 15) / 15)  # Normalize to 0-1\n",
    "                        lipinski_factor = lipinski_score / 4.0\n",
    "                        flexibility_factor = max(0, 1 - rotatable / 10)  # Prefer less flexible\n",
    "                        \n",
    "                        composite_score = (0.6 * affinity_score + \n",
    "                                         0.3 * lipinski_factor + \n",
    "                                         0.1 * flexibility_factor)\n",
    "                        \n",
    "                        result['composite_score'] = composite_score\n",
    "                        result['lipinski_score'] = lipinski_score\n",
    "                        result['molecular_properties'] = {\n",
    "                            'mw': mw, 'logp': logp, 'hbd': hbd, 'hba': hba, 'rotatable': rotatable\n",
    "                        }\n",
    "                \n",
    "                scored_results.append(result)\n",
    "            \n",
    "            # Rank by composite score (higher is better)\n",
    "            ranked = sorted(scored_results, \n",
    "                          key=lambda x: x.get('composite_score', -1), \n",
    "                          reverse=True)\n",
    "        \n",
    "        return ranked\n",
    "    \n",
    "    def generate_screening_report(self, ranked_results, top_n=50):\n",
    "        \"\"\"Generate comprehensive screening report\"\"\"\n",
    "        \n",
    "        print(\"üìã Virtual Screening Report\")\n",
    "        print(\"=\" * 35)\n",
    "        \n",
    "        # Overall statistics\n",
    "        total_compounds = len(ranked_results)\n",
    "        successful = len([r for r in ranked_results if r['status'] == 'success'])\n",
    "        failed = total_compounds - successful\n",
    "        \n",
    "        print(f\"\\nüìä Screening Statistics:\")\n",
    "        print(f\"   Total compounds screened: {total_compounds:,}\")\n",
    "        print(f\"   Successful dockings: {successful:,} ({successful/total_compounds*100:.1f}%)\")\n",
    "        print(f\"   Failed dockings: {failed:,} ({failed/total_compounds*100:.1f}%)\")\n",
    "        \n",
    "        if successful > 0:\n",
    "            successful_results = [r for r in ranked_results if r['status'] == 'success']\n",
    "            scores = [r['best_score'] for r in successful_results]\n",
    "            \n",
    "            print(f\"\\nüéØ Affinity Score Statistics:\")\n",
    "            print(f\"   Best score: {min(scores):.2f} kcal/mol\")\n",
    "            print(f\"   Worst score: {max(scores):.2f} kcal/mol\")\n",
    "            print(f\"   Mean score: {np.mean(scores):.2f} ¬± {np.std(scores):.2f} kcal/mol\")\n",
    "            print(f\"   Median score: {np.median(scores):.2f} kcal/mol\")\n",
    "            \n",
    "            # Count compounds with good binding\n",
    "            good_binders = len([s for s in scores if s <= -8.0])\n",
    "            excellent_binders = len([s for s in scores if s <= -10.0])\n",
    "            \n",
    "            print(f\"\\nüèÜ Binding Quality:\")\n",
    "            print(f\"   Excellent binders (‚â§ -10.0 kcal/mol): {excellent_binders} ({excellent_binders/successful*100:.1f}%)\")\n",
    "            print(f\"   Good binders (‚â§ -8.0 kcal/mol): {good_binders} ({good_binders/successful*100:.1f}%)\")\n",
    "            \n",
    "            # Top compounds\n",
    "            print(f\"\\nü•á Top {min(top_n, len(successful_results))} Compounds:\")\n",
    "            for i, result in enumerate(successful_results[:top_n], 1):\n",
    "                score = result['best_score']\n",
    "                smiles = result['smiles'][:50] + ('...' if len(result['smiles']) > 50 else '')\n",
    "                \n",
    "                status_line = f\"   {i:2d}. {row['Ligand']} ‚Üí {row['Protein']}: {row['Affinity']:.2f} kcal/mol\"\n",
    "                \n",
    "                if 'composite_score' in result:\n",
    "                    comp_score = result['composite_score']\n",
    "                    lipinski = result['lipinski_score']\n",
    "                    status_line += f\" | Composite: {comp_score:.3f} | Lipinski: {lipinski}/4\"\n",
    "                \n",
    "                print(status_line)\n",
    "        \n",
    "        return ranked_results[:top_n]\n",
    "    \n",
    "# Initialize screening pipeline\n",
    "screening_pipeline = VirtualScreeningPipeline(docking_engine)\n",
    "print(\"‚úÖ Virtual Screening Pipeline initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1808cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define molecular filters for drug-likeness\n",
    "def lipinski_filter(mol):\n",
    "    \"\"\"Lipinski's Rule of Five filter\"\"\"\n",
    "    mw = Descriptors.MolWt(mol)\n",
    "    logp = Descriptors.MolLogP(mol)\n",
    "    hbd = Descriptors.NumHDonors(mol)\n",
    "    hba = Descriptors.NumHAcceptors(mol)\n",
    "    \n",
    "    return (mw <= 500 and logp <= 5 and hbd <= 5 and hba <= 10)\n",
    "\n",
    "def veber_filter(mol):\n",
    "    \"\"\"Veber's rule filter (oral bioavailability)\"\"\"\n",
    "    rotatable = Descriptors.NumRotatableBonds(mol)\n",
    "    psa = Descriptors.TPSA(mol)\n",
    "    \n",
    "    return (rotatable <= 10 and psa <= 140)\n",
    "\n",
    "def pains_filter(mol):\n",
    "    \"\"\"Basic PAINS (Pan Assay Interference) filter\"\"\"\n",
    "    # Simplified PAINS patterns\n",
    "    pains_smarts = [\n",
    "        '[#6]1:[#6]:[#6]:[#6]2:[#6](:[#6]:1):[#6]:[#6]:[#6]:[#6]:2',  # Anthracene\n",
    "        'c1ccc2c(c1)c(=O)[nH]c(=O)2',  # Isatin\n",
    "        '[SH]',  # Free sulfhydryl\n",
    "        '[#6]=[#6]-[#6]=[#6]',  # Conjugated diene\n",
    "    ]\n",
    "    \n",
    "    for smarts in pains_smarts:\n",
    "        if mol.HasSubstructMatch(Chem.MolFromSmarts(smarts)):\n",
    "            return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def complexity_filter(mol):\n",
    "    \"\"\"Molecular complexity filter\"\"\"\n",
    "    heavy_atoms = mol.GetNumHeavyAtoms()\n",
    "    rings = Descriptors.RingCount(mol)\n",
    "    \n",
    "    # Reasonable complexity bounds\n",
    "    return (5 <= heavy_atoms <= 50 and rings <= 6)\n",
    "\n",
    "def reactive_groups_filter(mol):\n",
    "    \"\"\"Filter out highly reactive functional groups\"\"\"\n",
    "    reactive_smarts = [\n",
    "        '[C,c]=O',  # Aldehyde/ketone (simplified)\n",
    "        '[N+](=O)[O-]',  # Nitro group\n",
    "        'S(=O)(=O)Cl',  # Sulfonyl chloride\n",
    "        'C#N',  # Nitrile (can be reactive)\n",
    "        '[Cl,Br,I]',  # Halogens (simple filter)\n",
    "    ]\n",
    "    \n",
    "    reactive_count = 0\n",
    "    for smarts in reactive_smarts:\n",
    "        if mol.HasSubstructMatch(Chem.MolFromSmarts(smarts)):\n",
    "            reactive_count += 1\n",
    "    \n",
    "    # Allow some reactive groups but not too many\n",
    "    return reactive_count <= 2\n",
    "\n",
    "# Add filters to pipeline\n",
    "screening_pipeline.add_filter(lipinski_filter, \"Lipinski's Rule of Five\")\n",
    "screening_pipeline.add_filter(veber_filter, \"Veber's Rule\")\n",
    "screening_pipeline.add_filter(pains_filter, \"PAINS Filter\")\n",
    "screening_pipeline.add_filter(complexity_filter, \"Complexity Filter\")\n",
    "screening_pipeline.add_filter(reactive_groups_filter, \"Reactive Groups Filter\")\n",
    "\n",
    "print(f\"‚úÖ Added {len(screening_pipeline.filters)} molecular filters\")\n",
    "for filter_info in screening_pipeline.filters:\n",
    "    print(f\"   - {filter_info['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3b44b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate diverse compound library for virtual screening\n",
    "def generate_compound_library(size=200):\n",
    "    \"\"\"Generate diverse compound library for screening\"\"\"\n",
    "    \n",
    "    # Known drug and drug-like molecules for realistic screening\n",
    "    base_compounds = [\n",
    "        # Kinase inhibitors\n",
    "        'CCN(CC)CCNC(=O)C1=CC(=C(C=C1)OC)OC',  # Gefitinib-like\n",
    "        'CN1CCN(CC1)CC2=CC=C(C=C2)C(=O)NS(=O)(=O)C3=CC=C(C=C3)NCC4=CC=CC=C4',  # Sunitinib-like\n",
    "        \n",
    "        # Antibiotics\n",
    "        'CC1=C(C(=CC=C1)C)NC(=O)CN2CCN(CC2)C(=O)C3=CC=C(C=C3)F',  # Lincomycin-like\n",
    "        'CC(C)NC(=O)C1=NC=CN=C1C2=CC=C(C=C2)Cl',  # Chloramphenicol-like\n",
    "        \n",
    "        # Antiviral compounds\n",
    "        'NC1=NC(=O)C(=CN1)C2=CC=CC=C2',  # Nucleoside analog\n",
    "        'CC(C)(C)NC(=O)C1CC(C2=CC=CC=C2)C(=O)N1',  # Protease inhibitor scaffold\n",
    "        \n",
    "        # Natural product-like\n",
    "        'COC1=CC=C(C=C1)C2=COC3=C2C=CC(=C3)O',  # Flavonoid-like\n",
    "        'CC1=CC2=C(C=C1)N=C(N2)C3=CC=CC=C3',  # Indole-like\n",
    "        \n",
    "        # Diverse scaffolds\n",
    "        'CC1=NN(C=C1)C2=CC=C(C=C2)S(=O)(=O)N',  # Pyrazole\n",
    "        'CN1C=NC2=C1C(=O)N(C(=O)N2C)C',  # Purine analog\n",
    "    ]\n",
    "    \n",
    "    compounds = base_compounds.copy()\n",
    "    \n",
    "    # Generate variations and analogs\n",
    "    for base_smiles in base_compounds:\n",
    "        mol = Chem.MolFromSmiles(base_smiles)\n",
    "        if mol:\n",
    "            # Generate some random analogs (simplified)\n",
    "            for _ in range(size // len(base_compounds) - 1):\n",
    "                try:\n",
    "                    # Simple modification: add random substituents\n",
    "                    modified = modify_molecule(mol)\n",
    "                    if modified:\n",
    "                        compounds.append(Chem.MolToSmiles(modified))\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    # Fill remaining with additional diverse compounds\n",
    "    additional_compounds = [\n",
    "        'CC(C)C1=NC(=CS1)C(=O)N2CCN(CC2)C3=CC=C(C=C3)F',\n",
    "        'COC1=CC=C(C=C1)C2=NC3=CC=CC=C3S2',\n",
    "        'CC1=CC=C(C=C1)S(=O)(=O)NC2=CC=C(C=C2)C(=O)O',\n",
    "        'CN1C=NC2=C1C(=O)N(C(=O)N2C)C3=CC=CC=C3',\n",
    "        'CC(C)(C)OC(=O)NC1=CC=C(C=C1)C(=O)O',\n",
    "        'COC1=CC=C(C=C1)C2=CC(=NO2)C3=CC=CC=C3',\n",
    "        'CC1=CC=C(C=C1)NC(=O)C2=CC=C(C=C2)Br',\n",
    "        'CN1CCN(CC1)C2=NC3=CC=CC=C3O2',\n",
    "        'CC(C)NC(=O)C1=CC=C(C=C1)N2CCOCC2',\n",
    "        'COC1=CC=C(C=C1)C2=NC3=CC=CC=C3S2',\n",
    "    ]\n",
    "    \n",
    "    compounds.extend(additional_compounds)\n",
    "    \n",
    "    # Remove duplicates and limit size\n",
    "    unique_compounds = list(set(compounds))[:size]\n",
    "    \n",
    "    return unique_compounds\n",
    "\n",
    "def modify_molecule(mol):\n",
    "    \"\"\"Simple molecule modification for generating analogs\"\"\"\n",
    "    try:\n",
    "        # Make a copy\n",
    "        new_mol = Chem.RWMol(mol)\n",
    "        \n",
    "        # Simple modifications (very basic)\n",
    "        modifications = ['add_methyl', 'add_fluoro', 'add_hydroxyl']\n",
    "        modification = np.random.choice(modifications)\n",
    "        \n",
    "        if modification == 'add_methyl' and new_mol.GetNumAtoms() < 40:\n",
    "            # Find carbon atoms that can have methyl added\n",
    "            carbons = [atom.GetIdx() for atom in new_mol.GetAtoms() \n",
    "                      if atom.GetSymbol() == 'C' and atom.GetTotalValence() < 4]\n",
    "            \n",
    "            if carbons:\n",
    "                carbon_idx = np.random.choice(carbons)\n",
    "                methyl_idx = new_mol.AddAtom(Chem.Atom(6))  # Carbon\n",
    "                new_mol.AddBond(carbon_idx, methyl_idx, Chem.BondType.SINGLE)\n",
    "                \n",
    "                # Add hydrogens to methyl\n",
    "                for _ in range(3):\n",
    "                    h_idx = new_mol.AddAtom(Chem.Atom(1))  # Hydrogen\n",
    "                    new_mol.AddBond(methyl_idx, h_idx, Chem.BondType.SINGLE)\n",
    "        \n",
    "        # Sanitize and return\n",
    "        Chem.SanitizeMol(new_mol)\n",
    "        return new_mol.GetMol()\n",
    "        \n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Generate compound library\n",
    "print(\"üß™ Generating Compound Library for Virtual Screening:\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "compound_library = generate_compound_library(size=100)  # Manageable size for demo\n",
    "\n",
    "print(f\"‚úÖ Generated library of {len(compound_library)} compounds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f609f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply molecular filters to compound library first\n",
    "print(\"üîç Applying Molecular Filters to Compound Library:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "filtered_library = screening_pipeline.apply_filters(compound_library)\n",
    "\n",
    "# Run virtual screening on HIV protease\n",
    "target_protein = '3HTB'  # HIV-1 Protease\n",
    "\n",
    "if target_protein in docking_results and target_protein in receptor_pdbqts:\n",
    "    print(f\"üéØ Virtual Screening against {protein_data[target_protein]['name']}:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Get binding site center\n",
    "    center = docking_results[target_protein]['binding_center']\n",
    "    receptor_file = receptor_pdbqts[target_protein]\n",
    "    \n",
    "    print(f\"üìç Target: {protein_data[target_protein]['name']} ({target_protein})\")\n",
    "    print(f\"üìç Binding center: ({center['x']:.2f}, {center['y']:.2f}, {center['z']:.2f})\")\n",
    "    print(f\"üìç Compounds to screen: {len(filtered_library)}\")\n",
    "    \n",
    "    # Run parallel screening (smaller batch for demonstration)\n",
    "    screening_compounds = filtered_library[:30]  # Subset for demo\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    screening_results = screening_pipeline.parallel_docking(\n",
    "        receptor_file,\n",
    "        screening_compounds,\n",
    "        center,\n",
    "        max_workers=2,  # Conservative for demo\n",
    "        chunk_size=5\n",
    "    )\n",
    "    \n",
    "    screening_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  Screening completed in {screening_time:.2f} seconds\")\n",
    "    print(f\"‚è±Ô∏è  Average time per compound: {screening_time/len(screening_compounds):.2f} seconds\")\n",
    "    \n",
    "    # Rank results using composite scoring\n",
    "    print(\"\\nüìä Ranking Results...\")\n",
    "    ranked_results = screening_pipeline.rank_compounds(screening_results, 'composite')\n",
    "    \n",
    "    # Generate comprehensive report\n",
    "    top_hits = screening_pipeline.generate_screening_report(ranked_results, top_n=20)\n",
    "    \n",
    "    # Store results for further analysis\n",
    "    screening_pipeline.screening_results = ranked_results\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ùå Target protein {target_protein} not available for screening\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d40ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ Section 3 Completion Assessment: Virtual Screening Pipeline\n",
    "print(\"üéØ SECTION 3 COMPLETION ASSESSMENT: Virtual Screening Pipeline\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Record section completion\n",
    "section_3_concepts = [\n",
    "    \"compound_library_preparation\",\n",
    "    \"parallel_docking_implementation\", \n",
    "    \"screening_workflow_optimization\",\n",
    "    \"hit_identification_criteria\",\n",
    "    \"scoring_function_integration\",\n",
    "    \"virtual_screening_validation\",\n",
    "    \"hit_ranking_algorithms\"\n",
    "]\n",
    "\n",
    "section_3_activities = [\n",
    "    \"virtual_screening_pipeline_development\",\n",
    "    \"compound_library_processing\", \n",
    "    \"parallel_docking_execution\",\n",
    "    \"screening_optimization_strategies\",\n",
    "    \"hit_selection_workflows\",\n",
    "    \"scoring_integration_methods\",\n",
    "    \"screening_result_analysis\"\n",
    "]\n",
    "\n",
    "# Interactive assessment\n",
    "assessment_framework.create_completion_assessment(\n",
    "    section_name=\"Virtual Screening Pipeline\",\n",
    "    concepts=section_3_concepts,\n",
    "    activities=section_3_activities,\n",
    "    estimated_time_minutes=90,\n",
    "    specialization_focus={\n",
    "        'docking_expert': 'Advanced screening protocols and optimization',\n",
    "        'screening_specialist': 'High-throughput virtual screening implementation', \n",
    "        'ml_enhanced': 'Computational screening workflow integration',\n",
    "        'drug_discovery': 'Hit identification and lead optimization'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Record activity with specialization alignment\n",
    "student_specialization = globals().get('selected_specialization', 'general')\n",
    "assessment_framework.record_activity(\n",
    "    f\"day_3_section_3_completion_{student_specialization}\",\n",
    "    f\"Completed Section 3: Virtual Screening Pipeline with {student_specialization} focus\",\n",
    "    {\"section\": 3, \"specialization\": student_specialization, \"concepts_covered\": len(section_3_concepts)}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d78b9d",
   "metadata": {},
   "source": [
    "## Section 4: ML-Enhanced Scoring Functions (1 hour)\n",
    "\n",
    "**Objective:** Build machine learning models to improve docking score prediction and ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9268b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML-Enhanced Scoring Functions\n",
    "%pip install scikit-learn\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class MLScoringFunction:\n",
    "    \"\"\"Machine learning enhanced scoring function for docking\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        self.feature_names = []\n",
    "        \n",
    "    def calculate_molecular_features(self, smiles):\n",
    "        \"\"\"Calculate comprehensive molecular descriptors\"\"\"\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            if mol is None:\n",
    "                print(f\"‚ùå Invalid SMILES: {smiles}\")\n",
    "                return None\n",
    "                \n",
    "            # Add hydrogens for accurate calculations\n",
    "            mol = Chem.AddHs(mol)\n",
    "            \n",
    "            features = {\n",
    "                # Basic molecular properties\n",
    "                'mol_weight': Descriptors.MolWt(mol),\n",
    "                'logp': Descriptors.MolLogP(mol),\n",
    "                'tpsa': Descriptors.TPSA(mol),\n",
    "                'num_hbd': Descriptors.NumHDonors(mol),\n",
    "                'num_hba': Descriptors.NumHAcceptors(mol),\n",
    "                'num_rotatable_bonds': Descriptors.NumRotatableBonds(mol),\n",
    "                'num_aromatic_rings': Descriptors.NumAromaticRings(mol),\n",
    "                'num_heavy_atoms': mol.GetNumHeavyAtoms(),\n",
    "                \n",
    "                # Structural complexity\n",
    "                'bertz_ct': Descriptors.BertzCT(mol),\n",
    "                'balaban_j': Descriptors.BalabanJ(mol) if mol.GetNumAtoms() > 1 else 0,\n",
    "                'kappa1': Descriptors.Kappa1(mol),\n",
    "                'kappa2': Descriptors.Kappa2(mol),\n",
    "                'kappa3': Descriptors.Kappa3(mol),\n",
    "                \n",
    "                # Charge and polarity\n",
    "                'max_partial_charge': 0,  # Will be calculated below\n",
    "                'min_partial_charge': 0,\n",
    "                'num_heteroatoms': Descriptors.NumHeteroatoms(mol),\n",
    "                \n",
    "                # Shape descriptors\n",
    "                'asphericity': 0,  # Will be calculated below\n",
    "                'eccentricity': 0,\n",
    "                'inertial_shape_factor': 0,\n",
    "                \n",
    "                # Drug-likeness indicators\n",
    "                'lipinski_violations': sum([\n",
    "                    Descriptors.MolWt(mol) > 500,\n",
    "                    Descriptors.MolLogP(mol) > 5,\n",
    "                    Descriptors.NumHDonors(mol) > 5,\n",
    "                    Descriptors.NumHAcceptors(mol) > 10\n",
    "                ]),\n",
    "                \n",
    "                # Additional complexity measures\n",
    "                'ring_count': Descriptors.RingCount(mol),\n",
    "                'fused_ring_count': len([ring for ring in mol.GetRingInfo().AtomRings() if len(ring) > 6]),\n",
    "                'fraction_csp3': Descriptors.FractionCsp3(mol),\n",
    "            }\n",
    "            \n",
    "            # Calculate partial charges safely\n",
    "            try:\n",
    "                AllChem.ComputeGasteigerCharges(mol)\n",
    "                charges = [float(atom.GetProp('_GasteigerCharge')) for atom in mol.GetAtoms()]\n",
    "                charges = [c for c in charges if not np.isnan(c) and not np.isinf(c)]\n",
    "                if charges:\n",
    "                    features['max_partial_charge'] = max(charges)\n",
    "                    features['min_partial_charge'] = min(charges)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Charge calculation failed: {e}\")\n",
    "            \n",
    "            # Calculate 3D shape descriptors safely\n",
    "            try:\n",
    "                # Generate 3D conformation\n",
    "                AllChem.EmbedMolecule(mol, randomSeed=42)\n",
    "                AllChem.UFFOptimizeMolecule(mol)\n",
    "                \n",
    "                # Calculate shape descriptors\n",
    "                try:\n",
    "                    conf = mol.GetConformer()\n",
    "                    features['asphericity'] = Descriptors3D.Asphericity(mol)\n",
    "                    features['eccentricity'] = Descriptors3D.Eccentricity(mol)\n",
    "                    features['inertial_shape_factor'] = Descriptors3D.InertialShapeFactor(mol)\n",
    "                except:\n",
    "                    pass  # Keep default values\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è 3D shape calculation failed: {e}\")\n",
    "                \n",
    "            # ECFP fingerprint features (reduced for speed)\n",
    "            try:\n",
    "                fp = AllChem.GetMorganFingerprintAsBitVect(mol, 2, nBits=512)\n",
    "                fp_features = {f'ecfp_{i}': fp[i] for i in range(min(50, len(fp)))}  # Use first 50 bits\n",
    "                features.update(fp_features)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Fingerprint calculation failed: {e}\")\n",
    "                # Add dummy fingerprint features\n",
    "                fp_features = {f'ecfp_{i}': 0 for i in range(50)}\n",
    "                features.update(fp_features)\n",
    "            \n",
    "            return features\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Feature calculation failed for {smiles}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def prepare_training_data(self, docking_results_list):\n",
    "        \"\"\"Prepare training data from docking results\"\"\"\n",
    "        X_data = []\n",
    "        y_data = []\n",
    "        \n",
    "        print(\"üî¨ Preparing ML training data...\")\n",
    "        \n",
    "        valid_results = 0\n",
    "        for result in docking_results_list:\n",
    "            try:\n",
    "                if result.get('status') == 'success' and 'smiles' in result and 'best_score' in result:\n",
    "                    features = self.calculate_molecular_features(result['smiles'])\n",
    "                    \n",
    "                    if features:\n",
    "                        X_data.append(features)\n",
    "                        y_data.append(result['best_score'])\n",
    "                        valid_results += 1\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Error processing result: {e}\")\n",
    "                continue\n",
    "        \n",
    "        if not X_data:\n",
    "            print(\"‚ùå No valid training data available\")\n",
    "            return None, None\n",
    "        \n",
    "        # Convert to DataFrame for easier handling\n",
    "        try:\n",
    "            X_df = pd.DataFrame(X_data)\n",
    "            y_array = np.array(y_data)\n",
    "            \n",
    "            # Handle missing values\n",
    "            X_df = X_df.fillna(0)\n",
    "            \n",
    "            # Remove columns with zero variance\n",
    "            variance_mask = X_df.var() > 1e-8\n",
    "            X_df = X_df.loc[:, variance_mask]\n",
    "            \n",
    "            self.feature_names = X_df.columns.tolist()\n",
    "            \n",
    "            print(f\"‚úÖ Prepared training data: {len(X_df)} samples, {len(self.feature_names)} features\")\n",
    "            \n",
    "            return X_df.values, y_array\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Data preparation failed: {e}\")\n",
    "            return None, None\n",
    "    \n",
    "    def train_models(self, X, y, test_size=0.2):\n",
    "        \"\"\"Train multiple ML models for scoring function\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Validate input data\n",
    "            if X is None or y is None or len(X) == 0:\n",
    "                print(\"‚ùå Invalid training data\")\n",
    "                return {}\n",
    "                \n",
    "            if len(X) < 5:\n",
    "                print(\"‚ùå Insufficient training data (need at least 5 samples)\")\n",
    "                return {}\n",
    "            \n",
    "            # Split data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Scale features\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            \n",
    "            self.scalers['standard'] = scaler\n",
    "            \n",
    "            # Define models\n",
    "            models_to_train = {\n",
    "                'linear': LinearRegression(),\n",
    "                'random_forest': RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=1),\n",
    "                'gradient_boosting': GradientBoostingRegressor(n_estimators=50, random_state=42)\n",
    "            }\n",
    "            \n",
    "            print(\"ü§ñ Training ML Scoring Models:\")\n",
    "            print(\"=\" * 35)\n",
    "            \n",
    "            model_performance = {}\n",
    "            \n",
    "            for model_name, model in models_to_train.items():\n",
    "                try:\n",
    "                    print(f\"\\nüöÄ Training {model_name}...\")\n",
    "                    \n",
    "                    # Use scaled data for linear model, original for tree-based\n",
    "                    if model_name == 'linear':\n",
    "                        model.fit(X_train_scaled, y_train)\n",
    "                        y_pred = model.predict(X_test_scaled)\n",
    "                        cv_data = X_train_scaled\n",
    "                    else:\n",
    "                        model.fit(X_train, y_train)\n",
    "                        y_pred = model.predict(X_test)\n",
    "                        cv_data = X_train\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    mse = mean_squared_error(y_test, y_pred)\n",
    "                    r2 = r2_score(y_test, y_pred)\n",
    "                    rmse = np.sqrt(mse)\n",
    "                    \n",
    "                    # Cross-validation (with error handling)\n",
    "                    try:\n",
    "                        cv_scores = cross_val_score(model, cv_data, y_train, cv=min(5, len(y_train)//2), scoring='r2')\n",
    "                        cv_mean = cv_scores.mean()\n",
    "                        cv_std = cv_scores.std()\n",
    "                    except Exception as cv_e:\n",
    "                        print(f\"‚ö†Ô∏è Cross-validation failed: {cv_e}\")\n",
    "                        cv_mean = r2\n",
    "                        cv_std = 0.0\n",
    "                    \n",
    "                    performance = {\n",
    "                        'mse': mse,\n",
    "                        'rmse': rmse,\n",
    "                        'r2': r2,\n",
    "                        'cv_mean': cv_mean,\n",
    "                        'cv_std': cv_std\n",
    "                    }\n",
    "                    \n",
    "                    model_performance[model_name] = performance\n",
    "                    self.models[model_name] = model\n",
    "                    \n",
    "                    print(f\"   ‚úÖ RMSE: {rmse:.3f} kcal/mol\")\n",
    "                    print(f\"   ‚úÖ R¬≤: {r2:.3f}\")\n",
    "                    print(f\"   ‚úÖ CV R¬≤: {cv_mean:.3f} ¬± {cv_std:.3f}\")\n",
    "                    \n",
    "                except Exception as model_e:\n",
    "                    print(f\"‚ùå Failed to train {model_name}: {model_e}\")\n",
    "                    continue\n",
    "            \n",
    "            if model_performance:\n",
    "                # Determine best model\n",
    "                best_model_name = max(model_performance.keys(), \n",
    "                                    key=lambda k: model_performance[k]['r2'])\n",
    "                \n",
    "                print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "                print(f\"   R¬≤: {model_performance[best_model_name]['r2']:.3f}\")\n",
    "                \n",
    "                self.best_model_name = best_model_name\n",
    "            \n",
    "            return model_performance\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Model training failed: {e}\")\n",
    "            return {}\n",
    "    \n",
    "    def predict_affinity(self, smiles, model_name=None):\n",
    "        \"\"\"Predict binding affinity for a SMILES string\"\"\"\n",
    "        try:\n",
    "            if model_name is None:\n",
    "                model_name = getattr(self, 'best_model_name', 'random_forest')\n",
    "            \n",
    "            if model_name not in self.models:\n",
    "                print(f\"‚ùå Model {model_name} not available\")\n",
    "                return None\n",
    "            \n",
    "            features = self.calculate_molecular_features(smiles)\n",
    "            if features is None:\n",
    "                return None\n",
    "            \n",
    "            # Convert to array with correct feature order\n",
    "            X = np.array([features.get(fname, 0) for fname in self.feature_names]).reshape(1, -1)\n",
    "            \n",
    "            # Apply scaling if needed\n",
    "            if model_name == 'linear' and 'standard' in self.scalers:\n",
    "                X = self.scalers['standard'].transform(X)\n",
    "            \n",
    "            prediction = self.models[model_name].predict(X)[0]\n",
    "            \n",
    "            return prediction\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Prediction failed for {smiles}: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def analyze_feature_importance(self, model_name='random_forest', top_n=20):\n",
    "        \"\"\"Analyze feature importance for tree-based models\"\"\"\n",
    "        try:\n",
    "            if model_name not in self.models:\n",
    "                print(f\"‚ùå Model {model_name} not available\")\n",
    "                return None\n",
    "            \n",
    "            model = self.models[model_name]\n",
    "            \n",
    "            if hasattr(model, 'feature_importances_'):\n",
    "                importances = model.feature_importances_\n",
    "                \n",
    "                # Create feature importance DataFrame\n",
    "                feature_imp = pd.DataFrame({\n",
    "                    'feature': self.feature_names,\n",
    "                    'importance': importances\n",
    "                }).sort_values('importance', ascending=False)\n",
    "                \n",
    "                print(f\"üéØ Top {top_n} Most Important Features ({model_name}):\")\n",
    "                print(\"=\" * 50)\n",
    "                \n",
    "                for i, (_, row) in enumerate(feature_imp.head(top_n).iterrows(), 1):\n",
    "                    print(f\"   {i:2d}. {row['feature']:<25} {row['importance']:.4f}\")\n",
    "                \n",
    "                # Plot feature importance (with error handling)\n",
    "                try:\n",
    "                    plt.figure(figsize=(12, 8))\n",
    "                    top_features = feature_imp.head(top_n)\n",
    "                    \n",
    "                    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "                    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "                    plt.xlabel('Feature Importance', fontweight='bold')\n",
    "                    plt.title(f'Top {top_n} Feature Importances ({model_name})', fontweight='bold')\n",
    "                    plt.gca().invert_yaxis()\n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                except Exception as plot_e:\n",
    "                    print(f\"‚ö†Ô∏è Plotting failed: {plot_e}\")\n",
    "                \n",
    "                return feature_imp\n",
    "            else:\n",
    "                print(f\"‚ùå Model {model_name} does not have feature importance\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Feature importance analysis failed: {e}\")\n",
    "            return None\n",
    "\n",
    "# Initialize ML scoring function\n",
    "ml_scorer = MLScoringFunction()\n",
    "print(\"‚úÖ ML Scoring Function initialized\")\n",
    "\n",
    "# Train ML scoring models on screening results\n",
    "if hasattr(screening_pipeline, 'screening_results') and screening_pipeline.screening_results:\n",
    "    print(\"üß† Training ML-Enhanced Scoring Functions:\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Prepare training data\n",
    "    X, y = ml_scorer.prepare_training_data(screening_pipeline.screening_results)\n",
    "    \n",
    "    if X is not None and len(X) >= 10:  # Need minimum samples\n",
    "        # Train models\n",
    "        model_performance = ml_scorer.train_models(X, y)\n",
    "        \n",
    "        # Analyze feature importance\n",
    "        if model_performance:\n",
    "            feature_importance = ml_scorer.analyze_feature_importance('random_forest', top_n=15)\n",
    "        \n",
    "        # Test predictions on new molecules\n",
    "        test_molecules = [\n",
    "            'CC(C)C[C@H](NC(=O)[C@H](CC1=CC=CC=C1)NC(=O)OCc2ccccc2)C(=O)N[C@@H](Cc3c[nH]c4ccccc34)C(=O)O',\n",
    "            'COc1ccc(cc1)C2=CC(=O)c3c(O)cc(O)cc3O2',\n",
    "            'CC(C)(C)c1ccc(cc1)C(=O)NCCN2CCN(CC2)c3ccccn3'\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nüîÆ Testing ML Predictions:\")\n",
    "        print(\"=\" * 30)\n",
    "        \n",
    "        for i, smiles in enumerate(test_molecules, 1):\n",
    "            rf_pred = ml_scorer.predict_affinity(smiles, 'random_forest')\n",
    "            gb_pred = ml_scorer.predict_affinity(smiles, 'gradient_boosting')\n",
    "            \n",
    "            if rf_pred is not None:\n",
    "                print(f\"   Molecule {i}:\")\n",
    "                print(f\"      RF Prediction: {rf_pred:.2f} kcal/mol\")\n",
    "                if gb_pred is not None:\n",
    "                    print(f\"      GB Prediction: {gb_pred:.2f} kcal/mol\")\n",
    "                print(f\"      SMILES: {smiles[:60]}...\")\n",
    "    else:\n",
    "        print(\"‚ùå Insufficient training data for ML models\")\n",
    "else:\n",
    "    print(\"‚ùå No screening results available for ML training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d076458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
